{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c870a6ec",
   "metadata": {},
   "source": [
    "# GPT-Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f8a9309",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "324f9f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "\n",
    "torch.set_printoptions(precision=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a01468d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.35.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qml.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44818c2",
   "metadata": {},
   "source": [
    "Remember the convolution master formula: \n",
    "\n",
    "\n",
    "$\\frac{2p + w - k}{s} + 1 = d_{out}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35664602",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/environment/gpt-q/venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from models import QConv1d\n",
    "\n",
    "ks = 5  # kind of arbitrary, limited by the number of available qubits\n",
    "p = (ks - 1) // 2\n",
    "\n",
    "qconv = QConv1d(kernel_size=ks, out_channels=3, n_qlayers=1, stride=1, padding=p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7dc2403b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: ─╭AngleEmbedding(M0)─╭BasicEntanglerLayers(M1)─┤  <Z>\n",
      "1: ─├AngleEmbedding(M0)─├BasicEntanglerLayers(M1)─┤  <Z>\n",
      "2: ─├AngleEmbedding(M0)─├BasicEntanglerLayers(M1)─┤  <Z>\n",
      "3: ─├AngleEmbedding(M0)─├BasicEntanglerLayers(M1)─┤     \n",
      "4: ─╰AngleEmbedding(M0)─╰BasicEntanglerLayers(M1)─┤     \n",
      "\n",
      "M0 = \n",
      "[0.68798962 0.1920832  0.47135085 0.88375711 0.63174977]\n",
      "M1 = \n",
      "[[0.11413384 0.96416001 0.16161325 0.0685922  0.83082469]]\n"
     ]
    }
   ],
   "source": [
    "qconv.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "622958c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 8])\n",
      "tensor([[[6.888e-01, 6.105e-04, 2.041e-01, 5.558e-01, 4.643e-01, 6.439e-01,\n",
      "          1.240e-01, 2.507e-01],\n",
      "         [4.842e-01, 2.038e-01, 7.584e-01, 8.548e-01, 8.633e-01, 8.897e-02,\n",
      "          5.952e-01, 7.049e-01],\n",
      "         [5.892e-01, 7.538e-01, 8.009e-01, 4.951e-01, 2.938e-01, 4.290e-02,\n",
      "          9.473e-01, 5.127e-01],\n",
      "         [9.441e-01, 6.761e-01, 2.794e-01, 2.256e-01, 9.275e-01, 5.176e-01,\n",
      "          7.436e-01, 4.512e-01]]])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1\n",
    "seq_len = 4\n",
    "embed_dim = 8\n",
    "x = torch.rand((batch_size, seq_len, embed_dim))\n",
    "print(x.shape)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9bbe70b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 8, 3])\n"
     ]
    }
   ],
   "source": [
    "# here the output has 3 channels\n",
    "z = qconv(x)\n",
    "print(z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1717b98a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 8])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is a single channel\n",
    "z[:, :, :, 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4efc403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 24])\n"
     ]
    }
   ],
   "source": [
    "# we can flatten the output\n",
    "zc = z.view((1, 4, embed_dim*3))\n",
    "print(zc.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31cefb0",
   "metadata": {},
   "source": [
    "1 + (c*w + 2*p - k) / s = w\n",
    "=> (c*w - k) / s = w - 1\n",
    "=> s = (c*w - k) / (w - 1)\n",
    "this has to be an integer.\n",
    "\n",
    "n = (c*w - k) / (w - 1) => n * (w - 1) = c*w - k => k = c*w - n * (w - 1)\n",
    "k = (3 - n) * w + n, 0 < k < 3*w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc500c0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernel size (=no. of qubits): 3\n",
      "stride: 3\n",
      "0: ─╭AngleEmbedding(M0)─╭BasicEntanglerLayers(M1)─┤  <Z>\n",
      "1: ─├AngleEmbedding(M0)─├BasicEntanglerLayers(M1)─┤     \n",
      "2: ─╰AngleEmbedding(M0)─╰BasicEntanglerLayers(M1)─┤     \n",
      "\n",
      "M0 = \n",
      "[0.82112789 0.91236239 0.72302332]\n",
      "M1 = \n",
      "[[0.89164207 0.10621379 0.02582882]]\n"
     ]
    }
   ],
   "source": [
    "# to invert the convolution\n",
    "ks_inv = 3\n",
    "stride_inv = (3 * embed_dim - ks_inv) // (embed_dim - 1)\n",
    "print(f\"kernel size (=no. of qubits): {ks_inv}\")\n",
    "print(f\"stride: {stride_inv}\")\n",
    "qconv_inv = QConv1d(kernel_size=ks_inv, out_channels=1, n_qlayers=1, stride=stride_inv, padding=0)\n",
    "qconv_inv.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62d71b7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 8])\n"
     ]
    }
   ],
   "source": [
    "y = qconv_inv(zc).view((batch_size, seq_len, -1))\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0fcc08",
   "metadata": {},
   "source": [
    "### Vectorize input to CNN\n",
    "\n",
    "The code below creates indices for a sliding window of size `kernel_size`. To avoid loops, we can vectorize the operation using Numpy-like operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb071dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 8])\n",
      "tensor([[[0.800, 0.971, 0.705, 0.466, 0.235, 0.989, 0.965, 0.456],\n",
      "         [0.942, 0.890, 0.344, 0.925, 0.928, 0.731, 0.398, 0.784],\n",
      "         [0.137, 0.961, 0.788, 0.650, 0.911, 0.031, 0.206, 0.444],\n",
      "         [0.132, 0.113, 0.637, 0.263, 0.883, 0.210, 0.060, 0.687]]])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1\n",
    "seq_len = 4\n",
    "embed_dim = 8\n",
    "x = torch.rand((batch_size, seq_len, embed_dim))\n",
    "print(x.shape)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dee8bd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stride = 2\n",
    "kernel_size = 3\n",
    "padding = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e2a8c228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 8])\n",
      "out_dim: 3\n",
      "\n",
      "tensor([0.800, 0.971, 0.705])\n",
      "tensor([0.705, 0.466, 0.235])\n",
      "tensor([0.235, 0.989, 0.965])\n",
      "---\n",
      "tensor([0.942, 0.890, 0.344])\n",
      "tensor([0.344, 0.925, 0.928])\n",
      "tensor([0.928, 0.731, 0.398])\n",
      "---\n",
      "tensor([0.137, 0.961, 0.788])\n",
      "tensor([0.788, 0.650, 0.911])\n",
      "tensor([0.911, 0.031, 0.206])\n",
      "---\n",
      "tensor([0.132, 0.113, 0.637])\n",
      "tensor([0.637, 0.263, 0.883])\n",
      "tensor([0.883, 0.210, 0.060])\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "from torch.nn import functional as F\n",
    "\n",
    "# loops are slow!\n",
    "out_dim = int((embed_dim + 2 * padding - kernel_size) / stride) + 1\n",
    "z = F.pad(x, (padding, padding), \"constant\", 0)\n",
    "print(z.shape)\n",
    "print(f\"out_dim: {out_dim}\\n\")\n",
    "for i in range(batch_size):\n",
    "    for j in range(seq_len):\n",
    "        for k in range(0, out_dim):\n",
    "            k_start = k*stride\n",
    "            k_end = k_start + kernel_size\n",
    "            z_slice  = z[i, j, k_start:k_end]\n",
    "            print(z_slice)\n",
    "        print('---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9af9bc23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.800, 0.971, 0.705],\n",
       "         [0.942, 0.890, 0.344],\n",
       "         [0.137, 0.961, 0.788],\n",
       "         [0.132, 0.113, 0.637]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = np.arange(0, kernel_size)\n",
    "x[:,:,idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa58bb89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 2]\n",
      " [2 3 4]\n",
      " [4 5 6]]\n"
     ]
    }
   ],
   "source": [
    "# this creates a square matrix with correct indices\n",
    "idx = np.expand_dims(np.arange(kernel_size), 0) + np.expand_dims(np.arange(out_dim) * stride, 0).T\n",
    "print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "feb9c74b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.800, 0.971, 0.705],\n",
       "          [0.705, 0.466, 0.235],\n",
       "          [0.235, 0.989, 0.965]],\n",
       "\n",
       "         [[0.942, 0.890, 0.344],\n",
       "          [0.344, 0.925, 0.928],\n",
       "          [0.928, 0.731, 0.398]],\n",
       "\n",
       "         [[0.137, 0.961, 0.788],\n",
       "          [0.788, 0.650, 0.911],\n",
       "          [0.911, 0.031, 0.206]],\n",
       "\n",
       "         [[0.132, 0.113, 0.637],\n",
       "          [0.637, 0.263, 0.883],\n",
       "          [0.883, 0.210, 0.060]]]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this should match what is found using loops, but using vectorized indexing\n",
    "x[:,:,idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8dfcf6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import QConv1d\n",
    "\n",
    "qconv = QConv1d(kernel_size, stride=stride, padding=padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "067f02be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 3, 3])\n",
      "tensor([[[[ 0.020,  0.040,  0.040],\n",
      "          [-0.180, -0.340, -0.140],\n",
      "          [ 0.060,  0.060,  0.040]],\n",
      "\n",
      "         [[ 0.060,  0.000, -0.040],\n",
      "          [ 0.040,  0.020,  0.100],\n",
      "          [ 0.000, -0.100, -0.060]],\n",
      "\n",
      "         [[ 0.140,  0.100,  0.120],\n",
      "          [-0.320, -0.200, -0.120],\n",
      "          [-0.160, -0.380, -0.220]],\n",
      "\n",
      "         [[-0.480, -0.640, -0.460],\n",
      "          [-0.560, -0.480, -0.440],\n",
      "          [-0.180, -0.300, -0.100]]]], grad_fn=<ReshapeAliasBackward0>)\n"
     ]
    }
   ],
   "source": [
    "out = qconv(x)\n",
    "print(out.shape)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b819b77b",
   "metadata": {},
   "source": [
    "## FeedForward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4a16a754",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import FeedForwardQuantum\n",
    "\n",
    "embed_dim = 8\n",
    "n_qubits = 5\n",
    "n_qlayers = 1\n",
    "boom_factor = 4\n",
    "ff = FeedForwardQuantum(embed_dim, boom_factor=boom_factor, n_qubits=n_qubits, n_qlayers=n_qlayers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7b182954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: torch.Size([1, 4, 8])\n",
      "output: torch.Size([1, 4, 8])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1\n",
    "seq_len = 4\n",
    "embed_dim = 8\n",
    "x = torch.rand((batch_size, seq_len, embed_dim))\n",
    "\n",
    "print(\"input:\", x.shape)\n",
    "xff = ff.forward(x)\n",
    "print(\"output:\", xff.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3535403e",
   "metadata": {},
   "source": [
    "## Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f242bb6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 8])\n",
      "tensor([[[0.591, 0.855, 0.877, 0.949, 0.998, 0.049, 0.158, 0.510],\n",
      "         [0.100, 0.191, 0.937, 0.151, 0.918, 0.341, 0.825, 0.812],\n",
      "         [0.645, 0.525, 0.927, 0.836, 0.656, 0.865, 0.509, 0.723],\n",
      "         [0.742, 0.087, 0.442, 0.065, 0.640, 0.883, 0.628, 0.255]]])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1\n",
    "seq_len = 4\n",
    "embed_dim = 8\n",
    "x = torch.rand((batch_size, seq_len, embed_dim))\n",
    "print(x.shape)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "88b199fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import MultiHeadAttentionQuantum\n",
    "\n",
    "n_heads = 2\n",
    "n_qubits = 5\n",
    "n_qlayers = 1\n",
    "n_heads = 4\n",
    "\n",
    "attn = MultiHeadAttentionQuantum(embed_dim, n_heads, n_qubits, n_qlayers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ec263ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output of attention: torch.Size([1, 4, 8])\n"
     ]
    }
   ],
   "source": [
    "out = attn(x)\n",
    "print(\"output of attention:\", out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8c36ea",
   "metadata": {},
   "source": [
    "## Transformer block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "41632043",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import TransformerBlockQuantum\n",
    "\n",
    "transformer = TransformerBlockQuantum(embed_dim, n_heads=n_heads, n_qubits=n_qubits, n_qlayers=n_qlayers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e50e11a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformer block output: torch.Size([1, 4, 8])\n"
     ]
    }
   ],
   "source": [
    "x_tf = transformer.forward(x)\n",
    "print(\"transformer block output:\", x_tf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952e2ba0",
   "metadata": {},
   "source": [
    "## GPT-2 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5afc7b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import GPT2\n",
    "\n",
    "embed_dim = 8\n",
    "batch_size = 1\n",
    "max_seq_len = 16\n",
    "src_vocab = 8\n",
    "tgt_vocab = 4 \n",
    "n_tlayers = 2\n",
    "n_heads = 4\n",
    "\n",
    "gpt2 = GPT2(embed_dim=embed_dim,\n",
    "            src_vocab=src_vocab,\n",
    "            tgt_vocab=tgt_vocab,\n",
    "            n_heads=n_heads,\n",
    "            n_tlayers=n_tlayers,\n",
    "            max_seq_len=max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c93966d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 5, 1, 6, 0, 3, 0, 3, 4, 0, 2, 2, 1, 2, 1, 7]])\n"
     ]
    }
   ],
   "source": [
    "token_ids = np.random.choice(src_vocab, (batch_size, max_seq_len))\n",
    "token_ids = torch.tensor(token_ids)\n",
    "print(token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6f3479bd-7619-46db-9682-b6ac11a9795f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {\n",
    "    'input_ids': token_ids,\n",
    "    'attention_mask': torch.ones_like(token_ids),\n",
    "    'token_type_ids': torch.zeros_like(token_ids)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ff1dd346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.64 ms ± 223 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "GPT-2 output: torch.Size([1, 4, 8])\n"
     ]
    }
   ],
   "source": [
    "%timeit out = gpt2(inputs)\n",
    "print(\"GPT-2 output:\", out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c833898a",
   "metadata": {},
   "source": [
    "## GPT-Q Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a218f697",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import GPTQ\n",
    "\n",
    "n_qlayers = 1\n",
    "#q_device = \"default.qubit\"\n",
    "q_device = \"lightning.qubit\"\n",
    "\n",
    "gptq = GPTQ(embed_dim=embed_dim,\n",
    "            src_vocab=src_vocab,\n",
    "            tgt_vocab=tgt_vocab,\n",
    "            n_heads=n_heads,\n",
    "            n_tlayers=n_tlayers,\n",
    "            max_seq_len=max_seq_len,\n",
    "            n_qlayers=n_qlayers,\n",
    "            q_device=q_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3ae30c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.62 s ± 22.4 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "GPT-Q output: torch.Size([1, 4, 8])\n"
     ]
    }
   ],
   "source": [
    "%timeit out = gptq(inputs)\n",
    "print(\"GPT-Q output:\", out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4578d4",
   "metadata": {},
   "source": [
    "default.qubit: 6.14 s ± 485 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
    "\n",
    "lightning.qubit: 1.67 s ± 119 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "53ce97bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gptq.attn_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f377301e",
   "metadata": {},
   "source": [
    "## Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8dcbf381",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from utils import make_padding_mask, make_subsequent_mask, make_lookahead_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a1d1abea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 4 4 5]\n",
      " [5 4 7 5]]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 2\n",
    "max_seq_len = 4\n",
    "token_ids = np.random.choice(src_vocab, (batch_size, max_seq_len))\n",
    "#token_ids = torch.tensor(token_ids)\n",
    "print(token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ae24c391",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[True, True, True, True]],\n",
       "\n",
       "        [[True, True, True, True]]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_padding_mask(torch.Tensor(token_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "38650604",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f4b1655d670>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(make_subsequent_mask(max_seq_len)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cd7fff1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3, 0, 0],\n",
      "        [1, 2, 3, 4, 0]], dtype=torch.int32)\n",
      "tensor([[0., -inf, -inf, -inf, -inf],\n",
      "        [0., 0., -inf, -inf, -inf],\n",
      "        [0., 0., 0., -inf, -inf],\n",
      "        [0., 0., 0., 0., -inf],\n",
      "        [0., 0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "from utils import make_lookahead_mask, make_src_mask\n",
    "\n",
    "\n",
    "token_ids = np.array([\n",
    "    [1, 2, 3, 0, 0],\n",
    "    [1, 2, 3, 4, 0]\n",
    "], dtype=np.int32)\n",
    "token_ids = torch.from_numpy(token_ids)\n",
    "\n",
    "print(token_ids)\n",
    "print(make_src_mask(token_ids.size(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e6524986",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., -inf, -inf, -inf, -inf],\n",
       "        [0., 0., -inf, -inf, -inf],\n",
       "        [0., 0., 0., -inf, -inf],\n",
       "        [0., 0., 0., 0., -inf],\n",
       "        [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.Transformer().generate_square_subsequent_mask(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e1095742",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., -inf, -inf, -inf, -inf],\n",
       "        [0., 0., -inf, -inf, -inf],\n",
       "        [0., 0., 0., -inf, -inf],\n",
       "        [0., 0., 0., 0., -inf],\n",
       "        [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sz = 5\n",
    "torch.triu(torch.full((sz, sz), float('-inf')), diagonal=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d00099",
   "metadata": {},
   "source": [
    "## Train Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "054839e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.datasets import IMDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5b7fd779",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter, test_iter = IMDB(split=('train', 'test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "84da71ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "\"I Am Curious: Yellow\" is a risible and pretentious steaming pile. It doesn't matter what one's political views are because this film can hardly be taken seriously on any level. As for the claim that frontal male nudity is an automatic NC-17, that isn't true. I've seen R-rated films with male nudity. Granted, they only offer some fleeting views, but where are the R-rated films with gaping vulvas and flapping labia? Nowhere, because they don't exist. The same goes for those crappy cable shows: schlongs swinging in the breeze but not a clitoris in sight. And those pretentious indie movies like The Brown Bunny, in which we're treated to the site of Vincent Gallo's throbbing johnson, but not a trace of pink visible on Chloe Sevigny. Before crying (or implying) \"double-standard\" in matters of nudity, the mentally obtuse should take into account one unavoidably obvious anatomical difference between men and women: there are no genitals on display when actresses appears nude, and the same cannot be said for a man. In fact, you generally won't see female genitals in an American film in anything short of porn or explicit erotica. This alleged double-standard is less a double standard than an admittedly depressing ability to come to terms culturally with the insides of women's bodies.\n"
     ]
    }
   ],
   "source": [
    "train_data = []\n",
    "n_max = 1000\n",
    "for i, (label, line) in enumerate(train_iter):\n",
    "    if i >= n_max:\n",
    "        break\n",
    "    train_data.append(line)\n",
    "print(len(train_data))\n",
    "print(train_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9da8cc72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tokenizers import Tokenizer, models, normalizers, pre_tokenizers, decoders, trainers\n",
    "\n",
    "vocab_size = 300\n",
    "min_frequency = 2\n",
    "special_tokens = [\n",
    "        \"<s>\",\n",
    "        \"<pad>\",\n",
    "        \"</s>\",\n",
    "        \"<unk>\",\n",
    "        \"<mask>\",\n",
    "    ]\n",
    "\n",
    "tokenizer = Tokenizer(models.BPE())\n",
    "tokenizer.normalizer = normalizers.NFKC()\n",
    "tokenizer.pre_tokenizer = pre_tokenizers.ByteLevel()\n",
    "tokenizer.decoders = decoders.ByteLevel()\n",
    "\n",
    "trainer = trainers.BpeTrainer(\n",
    "    vocab_size=vocab_size,\n",
    "    initial_alphabet=pre_tokenizers.ByteLevel.alphabet(),\n",
    "    min_frequency=min_frequency,\n",
    "    special_tokens=special_tokens)\n",
    "\n",
    "tokenizer.train_from_iterator(train_data, trainer=trainer)\n",
    "tokenizer.save(\"gptq.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f40a6dab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[225, 44, 73, 286, 83, 268, 281, 80, 72]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"Hello world\").ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad77012",
   "metadata": {},
   "source": [
    "## Fit IMDb Sentiment Analysis Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "3002f26a-90d0-4dc3-b19c-8438e7ce65ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "({'input_ids': tensor([225,   6,  45, 225,  37,  81, 225,  39,  89,  86,  77, 282,  87,  30,\n",
      "        225,  61,  73, 286,  83,  91,   6, 225, 270, 262, 225,  86, 270,  77,\n",
      "         70,  80,  73, 290, 287, 267,  88, 280,  88,  77, 282,  87, 265,  88,\n",
      "         73,  69,  81, 278, 287,  77,  80,  73,  18, 297,  88, 289,  83, 283,\n",
      "         82,  11,  88, 273, 296,  88, 271, 268, 276,  88, 269,  82,  73,  11,\n",
      "         87, 287,  83,  80, 277,  77,  71,  69,  80, 225,  90,  77,  73,  91,\n",
      "         87, 262, 267, 272,  73,  71,  69,  89,  87,  73, 261,  76, 270, 274,\n",
      "         77,  80,  81, 279, 294, 225, 276,  86,  72,  80,  93, 272,  73, 261,\n",
      "         69,  79, 280, 265, 271,  77, 282,  87,  80,  93, 269,  82, 262,  82,\n",
      "         93, 292,  73,  90,  73,  80,  18, 225,  37,  87, 274, 281, 266, 279,\n",
      "         80,  69,  77,  81, 261, 276,  88, 274,  86, 284,  88,  69,  80, 273,\n",
      "         69,  80,  73, 225,  82,  89,  72, 277,  93, 225, 270, 262,  82, 262,\n",
      "         89,  88,  83,  81, 296,  77,  71, 225,  50,  39,  17,  21,  27,  16,\n",
      "        261, 276,  88, 225, 270,  82,  11,  88, 261,  86,  89,  73,  18, 297,\n",
      "         11,  90,  73, 265,  73, 280, 225,  54,  17,  86, 296, 291, 274,  77,\n",
      "         80,  81,  87, 268, 277,  76, 273,  69,  80,  73, 225,  82,  89,  72,\n",
      "        277,  93,  18, 225,  43,  86, 294,  88, 291,  16, 266,  93, 269,  82,\n",
      "         80,  93, 288,  74, 271, 265,  83,  81,  73, 274,  80,  73,  73,  88,\n",
      "        278, 225,  90,  77,  73,  91,  87,  16, 272,  89,  88, 268, 263, 267,\n",
      "        262, 267, 266, 225,  54,  17,  86, 296, 291, 274,  77,  80,  81,  87,\n",
      "        268, 277,  76, 225,  75,  69,  84, 278, 225,  90,  89,  80,  90, 295,\n",
      "        290, 274,  80,  69,  84,  84, 278, 292,  69,  70,  77,  69,  35, 225,\n",
      "         50,  83,  91, 263, 267,  16, 272,  73,  71,  69,  89,  87,  73, 266,\n",
      "         93, 289, 284,  11,  88, 225,  73,  92, 270,  88,  18, 225,  56, 263,\n",
      "        265,  69,  81,  73, 225,  75,  83, 283, 274, 281, 261,  76,  83,  87,\n",
      "         73, 279,  86,  69,  84,  84,  93, 279,  69,  70,  80,  73, 265,  76,\n",
      "         83,  91,  87,  30, 265,  71,  76,  80, 284,  75,  87, 265,  91, 278,\n",
      "        278, 293, 266, 272, 267,  73,  94,  73, 272,  89,  88, 225,  82,  83,\n",
      "         88, 262, 279,  80, 277, 281, 270, 293, 265,  77,  75,  76,  88,  18,\n",
      "        225,  37, 275, 261,  76,  83,  87,  73, 287, 267,  88, 280,  88,  77,\n",
      "        282,  87, 293,  72,  77,  73, 273,  83,  90,  77, 283, 292,  77,  79,\n",
      "         73, 225,  56, 263, 225,  38,  86,  83,  91,  82, 225,  38,  89,  82,\n",
      "         82,  93,  16, 293, 268,  76,  77,  71,  76, 268,  73,  11, 267, 261,\n",
      "        267, 296, 291, 285, 266, 265, 277,  73, 288, 225,  58, 264,  71, 280,\n",
      "         88, 225,  43,  69, 286,  83,  11,  87, 261,  76,  86,  83,  70,  70,\n",
      "        278, 225,  78,  83,  76,  82,  87, 284,  16, 272,  89,  88, 225,  82,\n",
      "         83,  88, 262, 261,  86,  69,  71,  73, 288, 287, 264,  79, 225,  90,\n",
      "        270,  77,  70,  80,  73, 269,  82, 225,  39,  76,  80,  83,  73, 225,\n",
      "         55,  73,  90,  77,  75,  82,  93,  18, 225,  38,  73,  74,  83, 267,\n",
      "        279,  86,  93, 278, 225,  12, 281, 225,  77,  81,  84,  80,  93, 278,\n",
      "         13, 225,   6,  72, 282,  70,  80,  73,  17,  87,  88,  69, 275,  69,\n",
      "         86,  72,   6, 293, 273, 296,  88, 271,  87, 288, 225,  82,  89,  72,\n",
      "        277,  93,  16, 266, 273, 280,  88,  69, 286,  93, 269,  70,  88,  89,\n",
      "         87,  73, 265,  76, 282,  80,  72, 261,  69,  79,  73, 293,  88,  83,\n",
      "        262,  71,  71, 282,  82,  88, 269,  82,  73, 225,  89,  82,  69,  90,\n",
      "         83,  77,  72,  69,  70,  80,  93, 269,  70,  90,  77, 282,  87, 262,\n",
      "         82, 296,  83,  81,  77,  71,  69,  80, 289,  77,  74,  74,  73, 267,\n",
      "         82,  71,  73, 272,  73,  88,  91,  73, 280, 273, 280, 290, 268,  83,\n",
      "         81, 280,  30, 266, 267, 262, 267, 225,  82,  83, 225,  75, 280, 277,\n",
      "         69,  80,  87, 269,  82, 289, 270,  84,  80,  69,  93, 268, 263,  82,\n",
      "        262,  71,  88, 267,  87,  87, 283, 262,  84,  84,  73,  69,  86,  87,\n",
      "        225,  82,  89,  72,  73,  16, 290, 266, 265,  69,  81,  73, 279, 294,\n",
      "         82,  83,  88, 272,  73, 265,  69,  77,  72, 274, 281, 262, 273, 294,\n",
      "         18, 297,  82, 274,  69,  71,  88,  16, 225,  93, 282, 225,  75, 280,\n",
      "        271,  69, 286,  93, 268, 284,  11,  88, 265,  73,  73, 274,  73,  81,\n",
      "         69,  80,  73, 225,  75, 280, 277,  69,  80,  87, 293, 262,  82, 225,\n",
      "         37,  81, 271,  77,  71, 294, 274,  77,  80,  81, 293, 262,  82,  93,\n",
      "         88,  76, 278, 265,  76, 281,  88, 288, 287, 281,  82, 269,  86, 225,\n",
      "         73,  92,  84,  80,  77,  71, 277, 225, 271,  83,  88,  77,  71,  69,\n",
      "         18, 225,  56,  76, 270, 262, 286,  73,  75, 291, 289, 282,  70,  80,\n",
      "         73,  17,  87,  88,  69, 275,  69,  86,  72, 225, 270, 292, 283,  87,\n",
      "        262, 289, 282,  70,  80,  73, 265,  88,  69, 275,  69,  86,  72, 261,\n",
      "        276,  82, 262,  82, 262,  72,  81, 277,  88, 291,  80,  93, 289,  73,\n",
      "         84, 267,  87,  87, 278, 262,  70,  77,  80, 277,  93, 285, 279,  83,\n",
      "         81,  73, 285, 261, 271,  81,  87, 279,  89,  80,  88,  89,  86,  69,\n",
      "        286,  93, 268, 277,  76, 266, 293,  87,  77,  72, 283, 288, 268,  83,\n",
      "         81, 280,  11,  87, 272,  83,  72,  77, 283,  18])}, 1)\n"
     ]
    }
   ],
   "source": [
    "train_data = []\n",
    "n_max = 100\n",
    "for i, (label, line) in enumerate(train_iter):\n",
    "    if i >= n_max:\n",
    "        break\n",
    "    token_ids = tokenizer.encode(line).ids\n",
    "    token_ids = torch.LongTensor(token_ids)\n",
    "    train_data.append(({'input_ids': token_ids}, label))\n",
    "train_loader = torch.utils.data.DataLoader(train_data)\n",
    "\n",
    "print(len(train_data))\n",
    "print(train_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "a8757d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import IMDbDataModule\n",
    "\n",
    "BATCH_SIZE = 4\n",
    "max_seq_len = 16\n",
    "n_examples_max = 16\n",
    "#n_examples_max = 8 # for quick tests\n",
    "#n_examples_max = None\n",
    "\n",
    "dm = IMDbDataModule(val_split=0.2,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    max_seq_length=max_seq_len,\n",
    "                    n_examples_max=n_examples_max)\n",
    "# train_loader = torch.utils.data.DataLoader(train_data)\n",
    "train_loader = torch.utils.data.DataLoader(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "ceea2a1d-15b0-44ad-a8a9-8b477df4d2a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'input_ids': tensor([[297, 225, 267,  ...,  83,  88,  18]])}, tensor([1])]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "661aeb97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "import lightning as L\n",
    "\n",
    "trainer = L.Trainer(\n",
    "    max_epochs=10,\n",
    "    accelerator='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "90ff0149",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import GPT2, IMDbClassifier\n",
    "\n",
    "embed_dim = 8\n",
    "vocab_size = 2000\n",
    "n_tlayers = 1\n",
    "n_heads = 2\n",
    "lr = 1e-3\n",
    "\n",
    "classifier = IMDbClassifier(embed_dim=embed_dim,\n",
    "                       vocab_size=vocab_size,\n",
    "                       n_heads=n_heads,\n",
    "                       n_tlayers=n_tlayers,\n",
    "                       max_seq_len=max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "f55ed28e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/environment/gpt-q/venv/lib/python3.9/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:653: Checkpoint directory /home/ec2-user/environment/gpt-q/lightning_logs/version_6/checkpoints exists and is not empty.\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | wte     | Embedding  | 2.4 K \n",
      "1 | wpe     | Embedding  | 128   \n",
      "2 | dropout | Dropout    | 0     \n",
      "3 | ln_f    | LayerNorm  | 16    \n",
      "4 | h       | ModuleList | 872   \n",
      "5 | out     | Linear     | 16.0 K\n",
      "---------------------------------------\n",
      "19.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "19.4 K    Total params\n",
      "0.078     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:  92%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████               | 92/100 [00:20<00:01,  4.40it/s, v_num=6]\n",
      "Epoch 9: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 102.20it/s, v_num=6]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 101.30it/s, v_num=6]\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(classifier, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "558a808c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(classifier.state_dict(), \"imdb_classifier.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b53e115",
   "metadata": {},
   "source": [
    "## IMBd Classifier Quantum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "86b43618",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import GPTQ, IMDbClassifierQuantum\n",
    "\n",
    "n_qlayers = 1\n",
    "q_device = 'qulacs.simulator'\n",
    "\n",
    "classifier_quantum = IMDbClassifierQuantum(embed_dim=embed_dim,\n",
    "                       vocab_size=vocab_size,\n",
    "                       n_heads=n_heads,\n",
    "                       n_tlayers=n_tlayers,\n",
    "                       max_seq_len=max_seq_len,\n",
    "                       q_device=q_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614c879b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | wte     | Embedding  | 2.4 K \n",
      "1 | wpe     | Embedding  | 128   \n",
      "2 | dropout | Dropout    | 0     \n",
      "3 | ln_f    | LayerNorm  | 16    \n",
      "4 | h       | ModuleList | 51    \n",
      "5 | out     | Linear     | 16.0 K\n",
      "---------------------------------------\n",
      "18.6 K    Trainable params\n",
      "0         Non-trainable params\n",
      "18.6 K    Total params\n",
      "0.074     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|                                                                                                                                                                                                            | 0/100 [28:51<?, ?it/s]\n",
      "Epoch 0:   0%|                                                                                                                                                                                                            | 0/100 [21:33<?, ?it/s]\n",
      "Epoch 0:   0%|                                                                                                                                                                                                            | 0/100 [14:54<?, ?it/s]\n",
      "Epoch 0:   0%|                                                                                                                                                                                                            | 0/100 [08:48<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "trainer_quantum = L.Trainer(\n",
    "    max_epochs=10,\n",
    "    accelerator='auto')\n",
    "\n",
    "trainer_quantum.fit(classifier_quantum, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c56a5d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(classifier_quantum.state_dict(), \"imdb_classifier_quantum.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85b50d3",
   "metadata": {},
   "source": [
    "## Fit Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "586234df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import LanguageModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "487b067c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 2000\n",
    "max_seq_len = 64\n",
    "n_layers = 1\n",
    "n_heads = 2\n",
    "lr = 1e-3\n",
    "\n",
    "model = LanguageModel(embed_dim=embed_dim,\n",
    "                       vocab_size=vocab_size,\n",
    "                       n_heads=n_heads,\n",
    "                       n_layers=n_layers,\n",
    "                       max_seq_len=max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91f62b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
