{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c870a6ec",
   "metadata": {},
   "source": [
    "# GPT-Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f8a9309",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-18T19:11:38.950891Z",
     "iopub.status.busy": "2024-03-18T19:11:38.950688Z",
     "iopub.status.idle": "2024-03-18T19:11:38.962436Z",
     "shell.execute_reply": "2024-03-18T19:11:38.962158Z",
     "shell.execute_reply.started": "2024-03-18T19:11:38.950879Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "324f9f28",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-18T19:11:38.963182Z",
     "iopub.status.busy": "2024-03-18T19:11:38.962968Z",
     "iopub.status.idle": "2024-03-18T19:11:40.260078Z",
     "shell.execute_reply": "2024-03-18T19:11:40.259566Z",
     "shell.execute_reply.started": "2024-03-18T19:11:38.963173Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "\n",
    "torch.set_printoptions(precision=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a01468d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-18T19:11:40.261107Z",
     "iopub.status.busy": "2024-03-18T19:11:40.260854Z",
     "iopub.status.idle": "2024-03-18T19:11:40.279784Z",
     "shell.execute_reply": "2024-03-18T19:11:40.279426Z",
     "shell.execute_reply.started": "2024-03-18T19:11:40.261095Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.35.1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qml.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44818c2",
   "metadata": {},
   "source": [
    "Remember the convolution master formula: \n",
    "\n",
    "\n",
    "$\\frac{2p + w - k}{s} + 1 = d_{out}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35664602",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-18T19:11:40.281078Z",
     "iopub.status.busy": "2024-03-18T19:11:40.280692Z",
     "iopub.status.idle": "2024-03-18T19:11:40.807032Z",
     "shell.execute_reply": "2024-03-18T19:11:40.806405Z",
     "shell.execute_reply.started": "2024-03-18T19:11:40.281066Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/idies/miniconda3/envs/qml/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from models import QConv1d\n",
    "\n",
    "ks = 5  # kind of arbitrary, limited by the number of available qubits\n",
    "p = (ks - 1) // 2\n",
    "\n",
    "qconv = QConv1d(kernel_size=ks, out_channels=3, n_qlayers=1, stride=1, padding=p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7dc2403b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-18T19:11:40.808134Z",
     "iopub.status.busy": "2024-03-18T19:11:40.807992Z",
     "iopub.status.idle": "2024-03-18T19:11:40.841927Z",
     "shell.execute_reply": "2024-03-18T19:11:40.841464Z",
     "shell.execute_reply.started": "2024-03-18T19:11:40.808121Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: ─╭AngleEmbedding(M0)─╭BasicEntanglerLayers(M1)─┤  <Z>\n",
      "1: ─├AngleEmbedding(M0)─├BasicEntanglerLayers(M1)─┤  <Z>\n",
      "2: ─├AngleEmbedding(M0)─├BasicEntanglerLayers(M1)─┤  <Z>\n",
      "3: ─├AngleEmbedding(M0)─├BasicEntanglerLayers(M1)─┤     \n",
      "4: ─╰AngleEmbedding(M0)─╰BasicEntanglerLayers(M1)─┤     \n",
      "\n",
      "M0 = \n",
      "[0.63003683 0.78306165 0.99153433 0.48376091 0.23132253]\n",
      "M1 = \n",
      "[[0.18178659 0.66181486 0.14047351 0.80888455 0.37789763]]\n"
     ]
    }
   ],
   "source": [
    "qconv.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "622958c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-18T19:11:40.842700Z",
     "iopub.status.busy": "2024-03-18T19:11:40.842503Z",
     "iopub.status.idle": "2024-03-18T19:11:40.864778Z",
     "shell.execute_reply": "2024-03-18T19:11:40.864333Z",
     "shell.execute_reply.started": "2024-03-18T19:11:40.842689Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 8])\n",
      "tensor([[[0.280, 0.613, 0.110, 0.453, 0.358, 0.926, 0.683, 0.158],\n",
      "         [0.488, 0.782, 0.252, 0.190, 0.880, 0.030, 0.195, 0.580],\n",
      "         [0.979, 0.041, 0.578, 0.145, 0.711, 0.138, 0.162, 0.020],\n",
      "         [0.392, 0.666, 0.728, 0.863, 0.136, 0.406, 0.163, 0.955]]])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1\n",
    "seq_len = 4\n",
    "embed_dim = 8\n",
    "x = torch.rand((batch_size, seq_len, embed_dim))\n",
    "print(x.shape)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9bbe70b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-18T19:11:40.865597Z",
     "iopub.status.busy": "2024-03-18T19:11:40.865286Z",
     "iopub.status.idle": "2024-03-18T19:11:41.010016Z",
     "shell.execute_reply": "2024-03-18T19:11:41.009458Z",
     "shell.execute_reply.started": "2024-03-18T19:11:40.865585Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 8, 3])\n"
     ]
    }
   ],
   "source": [
    "# here the output has 3 channels\n",
    "z = qconv(x)\n",
    "print(z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1717b98a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-18T19:11:41.010868Z",
     "iopub.status.busy": "2024-03-18T19:11:41.010634Z",
     "iopub.status.idle": "2024-03-18T19:11:41.037190Z",
     "shell.execute_reply": "2024-03-18T19:11:41.036827Z",
     "shell.execute_reply.started": "2024-03-18T19:11:41.010852Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 8])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is a single channel\n",
    "z[:, :, :, 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4efc403",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-18T19:11:41.037864Z",
     "iopub.status.busy": "2024-03-18T19:11:41.037686Z",
     "iopub.status.idle": "2024-03-18T19:11:41.057832Z",
     "shell.execute_reply": "2024-03-18T19:11:41.057445Z",
     "shell.execute_reply.started": "2024-03-18T19:11:41.037855Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 24])\n"
     ]
    }
   ],
   "source": [
    "# we can flatten the output\n",
    "zc = z.view((1, 4, embed_dim*3))\n",
    "print(zc.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31cefb0",
   "metadata": {},
   "source": [
    "1 + (c*w + 2*p - k) / s = w\n",
    "=> (c*w - k) / s = w - 1\n",
    "=> s = (c*w - k) / (w - 1)\n",
    "this has to be an integer.\n",
    "\n",
    "n = (c*w - k) / (w - 1) => n * (w - 1) = c*w - k => k = c*w - n * (w - 1)\n",
    "k = (3 - n) * w + n, 0 < k < 3*w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc500c0d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-18T19:11:41.059386Z",
     "iopub.status.busy": "2024-03-18T19:11:41.058964Z",
     "iopub.status.idle": "2024-03-18T19:11:41.082534Z",
     "shell.execute_reply": "2024-03-18T19:11:41.082148Z",
     "shell.execute_reply.started": "2024-03-18T19:11:41.059375Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernel size (=no. of qubits): 3\n",
      "stride: 3\n",
      "0: ─╭AngleEmbedding(M0)─╭BasicEntanglerLayers(M1)─┤  <Z>\n",
      "1: ─├AngleEmbedding(M0)─├BasicEntanglerLayers(M1)─┤     \n",
      "2: ─╰AngleEmbedding(M0)─╰BasicEntanglerLayers(M1)─┤     \n",
      "\n",
      "M0 = \n",
      "[0.49156757 0.92755915 0.81933734]\n",
      "M1 = \n",
      "[[0.5939204  0.52630589 0.43493933]]\n"
     ]
    }
   ],
   "source": [
    "# to invert the convolution\n",
    "ks_inv = 3\n",
    "stride_inv = (3 * embed_dim - ks_inv) // (embed_dim - 1)\n",
    "print(f\"kernel size (=no. of qubits): {ks_inv}\")\n",
    "print(f\"stride: {stride_inv}\")\n",
    "qconv_inv = QConv1d(kernel_size=ks_inv, out_channels=1, n_qlayers=1, stride=stride_inv, padding=0)\n",
    "qconv_inv.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62d71b7d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-18T19:11:41.083239Z",
     "iopub.status.busy": "2024-03-18T19:11:41.083053Z",
     "iopub.status.idle": "2024-03-18T19:11:41.113295Z",
     "shell.execute_reply": "2024-03-18T19:11:41.112831Z",
     "shell.execute_reply.started": "2024-03-18T19:11:41.083229Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 8])\n"
     ]
    }
   ],
   "source": [
    "y = qconv_inv(zc).view((batch_size, seq_len, -1))\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0fcc08",
   "metadata": {},
   "source": [
    "### Vectorize input to CNN\n",
    "\n",
    "The code below creates indices for a sliding window of size `kernel_size`. To avoid loops, we can vectorize the operation using Numpy-like operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb071dcf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-18T19:11:41.114009Z",
     "iopub.status.busy": "2024-03-18T19:11:41.113826Z",
     "iopub.status.idle": "2024-03-18T19:11:41.135264Z",
     "shell.execute_reply": "2024-03-18T19:11:41.134861Z",
     "shell.execute_reply.started": "2024-03-18T19:11:41.113999Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 8])\n",
      "tensor([[[0.244, 0.317, 0.888, 0.166, 0.043, 0.912, 0.702, 0.031],\n",
      "         [0.101, 0.847, 0.329, 0.332, 0.491, 0.147, 0.959, 0.212],\n",
      "         [0.788, 0.760, 0.890, 0.373, 0.556, 0.059, 0.577, 0.087],\n",
      "         [0.885, 0.356, 0.033, 0.939, 0.768, 0.577, 0.234, 0.991]]])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1\n",
    "seq_len = 4\n",
    "embed_dim = 8\n",
    "x = torch.rand((batch_size, seq_len, embed_dim))\n",
    "print(x.shape)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dee8bd6f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-18T19:11:41.135858Z",
     "iopub.status.busy": "2024-03-18T19:11:41.135754Z",
     "iopub.status.idle": "2024-03-18T19:11:41.155002Z",
     "shell.execute_reply": "2024-03-18T19:11:41.154626Z",
     "shell.execute_reply.started": "2024-03-18T19:11:41.135849Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "stride = 2\n",
    "kernel_size = 3\n",
    "padding = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e2a8c228",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-18T19:11:41.155557Z",
     "iopub.status.busy": "2024-03-18T19:11:41.155459Z",
     "iopub.status.idle": "2024-03-18T19:11:41.177840Z",
     "shell.execute_reply": "2024-03-18T19:11:41.177446Z",
     "shell.execute_reply.started": "2024-03-18T19:11:41.155549Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 8])\n",
      "out_dim: 3\n",
      "\n",
      "tensor([0.244, 0.317, 0.888])\n",
      "tensor([0.888, 0.166, 0.043])\n",
      "tensor([0.043, 0.912, 0.702])\n",
      "---\n",
      "tensor([0.101, 0.847, 0.329])\n",
      "tensor([0.329, 0.332, 0.491])\n",
      "tensor([0.491, 0.147, 0.959])\n",
      "---\n",
      "tensor([0.788, 0.760, 0.890])\n",
      "tensor([0.890, 0.373, 0.556])\n",
      "tensor([0.556, 0.059, 0.577])\n",
      "---\n",
      "tensor([0.885, 0.356, 0.033])\n",
      "tensor([0.033, 0.939, 0.768])\n",
      "tensor([0.768, 0.577, 0.234])\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "from torch.nn import functional as F\n",
    "\n",
    "# loops are slow!\n",
    "out_dim = int((embed_dim + 2 * padding - kernel_size) / stride) + 1\n",
    "z = F.pad(x, (padding, padding), \"constant\", 0)\n",
    "print(z.shape)\n",
    "print(f\"out_dim: {out_dim}\\n\")\n",
    "for i in range(batch_size):\n",
    "    for j in range(seq_len):\n",
    "        for k in range(0, out_dim):\n",
    "            k_start = k*stride\n",
    "            k_end = k_start + kernel_size\n",
    "            z_slice  = z[i, j, k_start:k_end]\n",
    "            print(z_slice)\n",
    "        print('---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9af9bc23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-18T19:11:41.178537Z",
     "iopub.status.busy": "2024-03-18T19:11:41.178356Z",
     "iopub.status.idle": "2024-03-18T19:11:41.198914Z",
     "shell.execute_reply": "2024-03-18T19:11:41.198569Z",
     "shell.execute_reply.started": "2024-03-18T19:11:41.178527Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.244, 0.317, 0.888],\n",
       "         [0.101, 0.847, 0.329],\n",
       "         [0.788, 0.760, 0.890],\n",
       "         [0.885, 0.356, 0.033]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = np.arange(0, kernel_size)\n",
    "x[:,:,idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa58bb89",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-18T19:11:41.199446Z",
     "iopub.status.busy": "2024-03-18T19:11:41.199351Z",
     "iopub.status.idle": "2024-03-18T19:11:41.219863Z",
     "shell.execute_reply": "2024-03-18T19:11:41.219426Z",
     "shell.execute_reply.started": "2024-03-18T19:11:41.199438Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 2]\n",
      " [2 3 4]\n",
      " [4 5 6]]\n"
     ]
    }
   ],
   "source": [
    "# this creates a square matrix with correct indices\n",
    "idx = np.expand_dims(np.arange(kernel_size), 0) + np.expand_dims(np.arange(out_dim) * stride, 0).T\n",
    "print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "feb9c74b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-18T19:11:41.220441Z",
     "iopub.status.busy": "2024-03-18T19:11:41.220340Z",
     "iopub.status.idle": "2024-03-18T19:11:41.240815Z",
     "shell.execute_reply": "2024-03-18T19:11:41.240475Z",
     "shell.execute_reply.started": "2024-03-18T19:11:41.220433Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.244, 0.317, 0.888],\n",
       "          [0.888, 0.166, 0.043],\n",
       "          [0.043, 0.912, 0.702]],\n",
       "\n",
       "         [[0.101, 0.847, 0.329],\n",
       "          [0.329, 0.332, 0.491],\n",
       "          [0.491, 0.147, 0.959]],\n",
       "\n",
       "         [[0.788, 0.760, 0.890],\n",
       "          [0.890, 0.373, 0.556],\n",
       "          [0.556, 0.059, 0.577]],\n",
       "\n",
       "         [[0.885, 0.356, 0.033],\n",
       "          [0.033, 0.939, 0.768],\n",
       "          [0.768, 0.577, 0.234]]]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this should match what is found using loops, but using vectorized indexing\n",
    "x[:,:,idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8dfcf6f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-18T19:11:41.241463Z",
     "iopub.status.busy": "2024-03-18T19:11:41.241289Z",
     "iopub.status.idle": "2024-03-18T19:11:41.261317Z",
     "shell.execute_reply": "2024-03-18T19:11:41.260923Z",
     "shell.execute_reply.started": "2024-03-18T19:11:41.241454Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from models import QConv1d\n",
    "\n",
    "qconv = QConv1d(kernel_size, stride=stride, padding=padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "067f02be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-18T19:11:41.262456Z",
     "iopub.status.busy": "2024-03-18T19:11:41.262273Z",
     "iopub.status.idle": "2024-03-18T19:11:41.288960Z",
     "shell.execute_reply": "2024-03-18T19:11:41.288511Z",
     "shell.execute_reply.started": "2024-03-18T19:11:41.262446Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 3, 3])\n",
      "tensor([[[[-0.220, -0.560, -0.180],\n",
      "          [-0.420, -0.440, -0.420],\n",
      "          [ 0.240,  0.160,  0.180]],\n",
      "\n",
      "         [[ 0.060, -0.020,  0.020],\n",
      "          [-0.200, -0.320, -0.180],\n",
      "          [-0.160, -0.640, -0.160]],\n",
      "\n",
      "         [[ 0.120, -0.020,  0.140],\n",
      "          [-0.180, -0.440, -0.180],\n",
      "          [-0.360, -0.800, -0.360]],\n",
      "\n",
      "         [[-0.440, -0.380, -0.420],\n",
      "          [ 0.020,  0.040, -0.100],\n",
      "          [-0.340, -0.300, -0.320]]]], grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "out = qconv(x)\n",
    "print(out.shape)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b819b77b",
   "metadata": {},
   "source": [
    "## FeedForward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4a16a754",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-18T19:11:41.662425Z",
     "iopub.status.busy": "2024-03-18T19:11:41.662077Z",
     "iopub.status.idle": "2024-03-18T19:11:41.690131Z",
     "shell.execute_reply": "2024-03-18T19:11:41.689727Z",
     "shell.execute_reply.started": "2024-03-18T19:11:41.662414Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from models import FeedForwardQuantum\n",
    "\n",
    "embed_dim = 8\n",
    "n_qubits = 5\n",
    "n_qlayers = 1\n",
    "boom_factor = 4\n",
    "ff = FeedForwardQuantum(embed_dim, boom_factor=boom_factor, n_qubits=n_qubits, n_qlayers=n_qlayers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7b182954",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-18T19:11:41.879494Z",
     "iopub.status.busy": "2024-03-18T19:11:41.879178Z",
     "iopub.status.idle": "2024-03-18T19:11:41.970014Z",
     "shell.execute_reply": "2024-03-18T19:11:41.969395Z",
     "shell.execute_reply.started": "2024-03-18T19:11:41.879481Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: torch.Size([1, 4, 8])\n",
      "output: torch.Size([1, 4, 8])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1\n",
    "seq_len = 4\n",
    "embed_dim = 8\n",
    "x = torch.rand((batch_size, seq_len, embed_dim))\n",
    "\n",
    "print(\"input:\", x.shape)\n",
    "xff = ff.forward(x)\n",
    "print(\"output:\", xff.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3535403e",
   "metadata": {},
   "source": [
    "## Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f242bb6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-18T19:11:42.547841Z",
     "iopub.status.busy": "2024-03-18T19:11:42.547633Z",
     "iopub.status.idle": "2024-03-18T19:11:42.575798Z",
     "shell.execute_reply": "2024-03-18T19:11:42.575293Z",
     "shell.execute_reply.started": "2024-03-18T19:11:42.547831Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 8])\n",
      "tensor([[[0.933, 0.684, 0.188, 0.582, 0.999, 0.608, 0.486, 0.168],\n",
      "         [0.650, 0.713, 0.845, 0.373, 0.215, 0.983, 0.830, 0.262],\n",
      "         [0.920, 0.402, 0.225, 0.444, 0.496, 0.085, 0.698, 0.786],\n",
      "         [0.420, 0.179, 0.272, 0.325, 0.632, 0.539, 0.226, 0.826]]])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1\n",
    "seq_len = 4\n",
    "embed_dim = 8\n",
    "x = torch.rand((batch_size, seq_len, embed_dim))\n",
    "print(x.shape)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "88b199fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-18T19:11:42.766331Z",
     "iopub.status.busy": "2024-03-18T19:11:42.765996Z",
     "iopub.status.idle": "2024-03-18T19:11:42.794025Z",
     "shell.execute_reply": "2024-03-18T19:11:42.793572Z",
     "shell.execute_reply.started": "2024-03-18T19:11:42.766319Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from models import MultiHeadAttentionQuantum\n",
    "\n",
    "n_heads = 2\n",
    "n_qubits = 5\n",
    "n_qlayers = 1\n",
    "n_heads = 4\n",
    "\n",
    "attn = MultiHeadAttentionQuantum(embed_dim, n_heads, n_qubits, n_qlayers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ec263ac6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-18T19:11:42.977239Z",
     "iopub.status.busy": "2024-03-18T19:11:42.976998Z",
     "iopub.status.idle": "2024-03-18T19:11:43.034017Z",
     "shell.execute_reply": "2024-03-18T19:11:43.033533Z",
     "shell.execute_reply.started": "2024-03-18T19:11:42.977228Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output of attention: torch.Size([1, 4, 8])\n"
     ]
    }
   ],
   "source": [
    "out = attn(x)\n",
    "print(\"output of attention:\", out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8c36ea",
   "metadata": {},
   "source": [
    "## Transformer block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "41632043",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-18T19:11:44.024865Z",
     "iopub.status.busy": "2024-03-18T19:11:44.024657Z",
     "iopub.status.idle": "2024-03-18T19:11:44.052896Z",
     "shell.execute_reply": "2024-03-18T19:11:44.052453Z",
     "shell.execute_reply.started": "2024-03-18T19:11:44.024854Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from models import TransformerBlockQuantum\n",
    "\n",
    "transformer = TransformerBlockQuantum(embed_dim, n_heads=n_heads, n_qubits=n_qubits, n_qlayers=n_qlayers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e50e11a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-18T19:11:44.390872Z",
     "iopub.status.busy": "2024-03-18T19:11:44.390669Z",
     "iopub.status.idle": "2024-03-18T19:11:44.544930Z",
     "shell.execute_reply": "2024-03-18T19:11:44.544364Z",
     "shell.execute_reply.started": "2024-03-18T19:11:44.390862Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformer block output: torch.Size([1, 4, 8])\n"
     ]
    }
   ],
   "source": [
    "x_tf = transformer.forward(x)\n",
    "print(\"transformer block output:\", x_tf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952e2ba0",
   "metadata": {},
   "source": [
    "## GPT-2 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5afc7b5d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-18T19:11:45.606073Z",
     "iopub.status.busy": "2024-03-18T19:11:45.605865Z",
     "iopub.status.idle": "2024-03-18T19:11:45.639017Z",
     "shell.execute_reply": "2024-03-18T19:11:45.638532Z",
     "shell.execute_reply.started": "2024-03-18T19:11:45.606063Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from models import GPT2\n",
    "\n",
    "embed_dim = 8\n",
    "batch_size = 1\n",
    "max_seq_len = 16\n",
    "src_vocab = 8\n",
    "tgt_vocab = 4 \n",
    "n_tlayers = 2\n",
    "n_heads = 4\n",
    "\n",
    "gpt2 = GPT2(embed_dim=embed_dim,\n",
    "            src_vocab=src_vocab,\n",
    "            tgt_vocab=tgt_vocab,\n",
    "            n_heads=n_heads,\n",
    "            n_tlayers=n_tlayers,\n",
    "            max_seq_len=max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c93966d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-18T19:11:46.204794Z",
     "iopub.status.busy": "2024-03-18T19:11:46.204474Z",
     "iopub.status.idle": "2024-03-18T19:11:46.232189Z",
     "shell.execute_reply": "2024-03-18T19:11:46.231683Z",
     "shell.execute_reply.started": "2024-03-18T19:11:46.204781Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3, 4, 1, 5, 3, 1, 0, 4, 3, 6, 0, 2, 3, 2, 3, 7]])\n"
     ]
    }
   ],
   "source": [
    "token_ids = np.random.choice(src_vocab, (batch_size, max_seq_len))\n",
    "token_ids = torch.tensor(token_ids)\n",
    "print(token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6f3479bd-7619-46db-9682-b6ac11a9795f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-18T19:11:46.767501Z",
     "iopub.status.busy": "2024-03-18T19:11:46.767179Z",
     "iopub.status.idle": "2024-03-18T19:11:46.797031Z",
     "shell.execute_reply": "2024-03-18T19:11:46.793893Z",
     "shell.execute_reply.started": "2024-03-18T19:11:46.767490Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "inputs = {\n",
    "    'input_ids': token_ids,\n",
    "    'attention_mask': torch.ones_like(token_ids),\n",
    "    'token_type_ids': torch.zeros_like(token_ids)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ff1dd346",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-18T19:11:47.763687Z",
     "iopub.status.busy": "2024-03-18T19:11:47.763308Z",
     "iopub.status.idle": "2024-03-18T19:11:53.407391Z",
     "shell.execute_reply": "2024-03-18T19:11:53.406684Z",
     "shell.execute_reply.started": "2024-03-18T19:11:47.763676Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.69 ms ± 934 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "GPT-2 output: torch.Size([1, 4, 8])\n"
     ]
    }
   ],
   "source": [
    "%timeit out = gpt2(inputs)\n",
    "print(\"GPT-2 output:\", out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c833898a",
   "metadata": {},
   "source": [
    "## GPT-Q Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a218f697",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-18T19:12:11.944875Z",
     "iopub.status.busy": "2024-03-18T19:12:11.944498Z",
     "iopub.status.idle": "2024-03-18T19:12:11.986096Z",
     "shell.execute_reply": "2024-03-18T19:12:11.985491Z",
     "shell.execute_reply.started": "2024-03-18T19:12:11.944859Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from models import GPTQ\n",
    "\n",
    "n_qlayers = 1\n",
    "#q_device = \"default.qubit\"\n",
    "q_device = \"lightning.qubit\"\n",
    "\n",
    "gptq = GPTQ(embed_dim=embed_dim,\n",
    "            src_vocab=src_vocab,\n",
    "            tgt_vocab=tgt_vocab,\n",
    "            n_heads=n_heads,\n",
    "            n_tlayers=n_tlayers,\n",
    "            max_seq_len=max_seq_len,\n",
    "            n_qlayers=n_qlayers,\n",
    "            q_device=q_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3ae30c2e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-18T19:12:13.171677Z",
     "iopub.status.busy": "2024-03-18T19:12:13.171323Z",
     "iopub.status.idle": "2024-03-18T19:12:16.456771Z",
     "shell.execute_reply": "2024-03-18T19:12:16.456132Z",
     "shell.execute_reply.started": "2024-03-18T19:12:13.171663Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "397 ms ± 15 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "GPT-Q output: torch.Size([1, 4, 8])\n"
     ]
    }
   ],
   "source": [
    "%timeit out = gptq(inputs)\n",
    "print(\"GPT-Q output:\", out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4578d4",
   "metadata": {},
   "source": [
    "default.qubit: 6.14 s ± 485 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
    "\n",
    "lightning.qubit: 1.67 s ± 119 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "53ce97bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-18T19:12:16.457843Z",
     "iopub.status.busy": "2024-03-18T19:12:16.457682Z",
     "iopub.status.idle": "2024-03-18T19:12:16.491553Z",
     "shell.execute_reply": "2024-03-18T19:12:16.491137Z",
     "shell.execute_reply.started": "2024-03-18T19:12:16.457831Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gptq.attn_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f377301e",
   "metadata": {},
   "source": [
    "## Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8dcbf381",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-18T19:12:16.492253Z",
     "iopub.status.busy": "2024-03-18T19:12:16.492102Z",
     "iopub.status.idle": "2024-03-18T19:12:16.518963Z",
     "shell.execute_reply": "2024-03-18T19:12:16.518529Z",
     "shell.execute_reply.started": "2024-03-18T19:12:16.492241Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from utils import make_padding_mask, make_subsequent_mask, make_lookahead_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a1d1abea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-18T19:12:16.700363Z",
     "iopub.status.busy": "2024-03-18T19:12:16.700136Z",
     "iopub.status.idle": "2024-03-18T19:12:16.728880Z",
     "shell.execute_reply": "2024-03-18T19:12:16.728412Z",
     "shell.execute_reply.started": "2024-03-18T19:12:16.700352Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6 2 4 6]\n",
      " [0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 2\n",
    "max_seq_len = 4\n",
    "token_ids = np.random.choice(src_vocab, (batch_size, max_seq_len))\n",
    "#token_ids = torch.tensor(token_ids)\n",
    "print(token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ae24c391",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-18T19:12:17.357999Z",
     "iopub.status.busy": "2024-03-18T19:12:17.357769Z",
     "iopub.status.idle": "2024-03-18T19:12:17.386783Z",
     "shell.execute_reply": "2024-03-18T19:12:17.386403Z",
     "shell.execute_reply.started": "2024-03-18T19:12:17.357987Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ True,  True,  True,  True]],\n",
       "\n",
       "        [[False, False, False, False]]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_padding_mask(torch.Tensor(token_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "38650604",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-18T19:12:17.929107Z",
     "iopub.status.busy": "2024-03-18T19:12:17.928875Z",
     "iopub.status.idle": "2024-03-18T19:12:18.054256Z",
     "shell.execute_reply": "2024-03-18T19:12:18.053833Z",
     "shell.execute_reply.started": "2024-03-18T19:12:17.929094Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fdda4650e50>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(make_subsequent_mask(max_seq_len)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cd7fff1f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-18T19:12:18.736769Z",
     "iopub.status.busy": "2024-03-18T19:12:18.736539Z",
     "iopub.status.idle": "2024-03-18T19:12:18.769985Z",
     "shell.execute_reply": "2024-03-18T19:12:18.769495Z",
     "shell.execute_reply.started": "2024-03-18T19:12:18.736757Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3, 0, 0],\n",
      "        [1, 2, 3, 4, 0]], dtype=torch.int32)\n",
      "tensor([[0., -inf, -inf, -inf, -inf],\n",
      "        [0., 0., -inf, -inf, -inf],\n",
      "        [0., 0., 0., -inf, -inf],\n",
      "        [0., 0., 0., 0., -inf],\n",
      "        [0., 0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "from utils import make_lookahead_mask, make_src_mask\n",
    "\n",
    "\n",
    "token_ids = np.array([\n",
    "    [1, 2, 3, 0, 0],\n",
    "    [1, 2, 3, 4, 0]\n",
    "], dtype=np.int32)\n",
    "token_ids = torch.from_numpy(token_ids)\n",
    "\n",
    "print(token_ids)\n",
    "print(make_src_mask(token_ids.size(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e6524986",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-18T19:12:21.129118Z",
     "iopub.status.busy": "2024-03-18T19:12:21.128891Z",
     "iopub.status.idle": "2024-03-18T19:12:21.454944Z",
     "shell.execute_reply": "2024-03-18T19:12:21.454431Z",
     "shell.execute_reply.started": "2024-03-18T19:12:21.129106Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/idies/miniconda3/envs/qml/lib/python3.11/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0., -inf, -inf, -inf, -inf],\n",
       "        [0., 0., -inf, -inf, -inf],\n",
       "        [0., 0., 0., -inf, -inf],\n",
       "        [0., 0., 0., 0., -inf],\n",
       "        [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.Transformer().generate_square_subsequent_mask(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e1095742",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-18T19:12:22.951716Z",
     "iopub.status.busy": "2024-03-18T19:12:22.951082Z",
     "iopub.status.idle": "2024-03-18T19:12:22.991730Z",
     "shell.execute_reply": "2024-03-18T19:12:22.991217Z",
     "shell.execute_reply.started": "2024-03-18T19:12:22.951696Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., -inf, -inf, -inf, -inf],\n",
       "        [0., 0., -inf, -inf, -inf],\n",
       "        [0., 0., 0., -inf, -inf],\n",
       "        [0., 0., 0., 0., -inf],\n",
       "        [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sz = 5\n",
    "torch.triu(torch.full((sz, sz), float('-inf')), diagonal=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d00099",
   "metadata": {},
   "source": [
    "## Train Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "054839e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-18T19:12:24.417893Z",
     "iopub.status.busy": "2024-03-18T19:12:24.417566Z",
     "iopub.status.idle": "2024-03-18T19:12:24.490833Z",
     "shell.execute_reply": "2024-03-18T19:12:24.490305Z",
     "shell.execute_reply.started": "2024-03-18T19:12:24.417881Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchtext.datasets import IMDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5b7fd779",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-18T19:12:25.400563Z",
     "iopub.status.busy": "2024-03-18T19:12:25.400248Z",
     "iopub.status.idle": "2024-03-18T19:12:25.438541Z",
     "shell.execute_reply": "2024-03-18T19:12:25.438118Z",
     "shell.execute_reply.started": "2024-03-18T19:12:25.400550Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_iter, test_iter = IMDB(split=('train', 'test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "84da71ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-18T19:12:25.999057Z",
     "iopub.status.busy": "2024-03-18T19:12:25.998852Z",
     "iopub.status.idle": "2024-03-18T19:12:26.153672Z",
     "shell.execute_reply": "2024-03-18T19:12:26.153150Z",
     "shell.execute_reply.started": "2024-03-18T19:12:25.999044Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "\"I Am Curious: Yellow\" is a risible and pretentious steaming pile. It doesn't matter what one's political views are because this film can hardly be taken seriously on any level. As for the claim that frontal male nudity is an automatic NC-17, that isn't true. I've seen R-rated films with male nudity. Granted, they only offer some fleeting views, but where are the R-rated films with gaping vulvas and flapping labia? Nowhere, because they don't exist. The same goes for those crappy cable shows: schlongs swinging in the breeze but not a clitoris in sight. And those pretentious indie movies like The Brown Bunny, in which we're treated to the site of Vincent Gallo's throbbing johnson, but not a trace of pink visible on Chloe Sevigny. Before crying (or implying) \"double-standard\" in matters of nudity, the mentally obtuse should take into account one unavoidably obvious anatomical difference between men and women: there are no genitals on display when actresses appears nude, and the same cannot be said for a man. In fact, you generally won't see female genitals in an American film in anything short of porn or explicit erotica. This alleged double-standard is less a double standard than an admittedly depressing ability to come to terms culturally with the insides of women's bodies.\n"
     ]
    }
   ],
   "source": [
    "train_data = []\n",
    "n_max = 1000\n",
    "for i, (label, line) in enumerate(train_iter):\n",
    "    if i >= n_max:\n",
    "        break\n",
    "    train_data.append(line)\n",
    "print(len(train_data))\n",
    "print(train_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9da8cc72",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-18T19:12:27.079501Z",
     "iopub.status.busy": "2024-03-18T19:12:27.079299Z",
     "iopub.status.idle": "2024-03-18T19:12:27.293016Z",
     "shell.execute_reply": "2024-03-18T19:12:27.292472Z",
     "shell.execute_reply.started": "2024-03-18T19:12:27.079489Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tokenizers import Tokenizer, models, normalizers, pre_tokenizers, decoders, trainers\n",
    "\n",
    "vocab_size = 300\n",
    "min_frequency = 2\n",
    "special_tokens = [\n",
    "        \"<s>\",\n",
    "        \"<pad>\",\n",
    "        \"</s>\",\n",
    "        \"<unk>\",\n",
    "        \"<mask>\",\n",
    "    ]\n",
    "\n",
    "tokenizer = Tokenizer(models.BPE())\n",
    "tokenizer.normalizer = normalizers.NFKC()\n",
    "tokenizer.pre_tokenizer = pre_tokenizers.ByteLevel()\n",
    "tokenizer.decoders = decoders.ByteLevel()\n",
    "\n",
    "trainer = trainers.BpeTrainer(\n",
    "    vocab_size=vocab_size,\n",
    "    initial_alphabet=pre_tokenizers.ByteLevel.alphabet(),\n",
    "    min_frequency=min_frequency,\n",
    "    special_tokens=special_tokens)\n",
    "\n",
    "tokenizer.train_from_iterator(train_data, trainer=trainer)\n",
    "tokenizer.save(\"gptq.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f40a6dab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-18T19:12:28.002280Z",
     "iopub.status.busy": "2024-03-18T19:12:28.002065Z",
     "iopub.status.idle": "2024-03-18T19:12:28.030824Z",
     "shell.execute_reply": "2024-03-18T19:12:28.030438Z",
     "shell.execute_reply.started": "2024-03-18T19:12:28.002268Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[225, 44, 73, 286, 83, 268, 281, 80, 72]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"Hello world\").ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad77012",
   "metadata": {},
   "source": [
    "## Fit IMDb Sentiment Analysis Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3002f26a-90d0-4dc3-b19c-8438e7ce65ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-18T20:36:12.711158Z",
     "iopub.status.busy": "2024-03-18T20:36:12.710983Z",
     "iopub.status.idle": "2024-03-18T20:36:12.923996Z",
     "shell.execute_reply": "2024-03-18T20:36:12.923561Z",
     "shell.execute_reply.started": "2024-03-18T20:36:12.711148Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "({'input_ids': tensor([225,   6,  45, 225,  37,  81, 225,  39,  89,  86,  77, 282,  87,  30,\n",
      "        225,  61,  73, 286,  83,  91,   6, 225, 270, 262, 225,  86, 270,  77,\n",
      "         70,  80,  73, 290, 287, 267,  88, 280,  88,  77, 282,  87, 265,  88,\n",
      "         73,  69,  81, 278, 287,  77,  80,  73,  18, 297,  88, 289,  83, 283,\n",
      "         82,  11,  88, 273, 296,  88, 271, 268, 276,  88, 269,  82,  73,  11,\n",
      "         87, 287,  83,  80, 277,  77,  71,  69,  80, 225,  90,  77,  73,  91,\n",
      "         87, 262, 267, 272,  73,  71,  69,  89,  87,  73, 261,  76, 270, 274,\n",
      "         77,  80,  81, 279, 294, 225, 276,  86,  72,  80,  93, 272,  73, 261,\n",
      "         69,  79, 280, 265, 271,  77, 282,  87,  80,  93, 269,  82, 262,  82,\n",
      "         93, 292,  73,  90,  73,  80,  18, 225,  37,  87, 274, 281, 266, 279,\n",
      "         80,  69,  77,  81, 261, 276,  88, 274,  86, 284,  88,  69,  80, 273,\n",
      "         69,  80,  73, 225,  82,  89,  72, 277,  93, 225, 270, 262,  82, 262,\n",
      "         89,  88,  83,  81, 296,  77,  71, 225,  50,  39,  17,  21,  27,  16,\n",
      "        261, 276,  88, 225, 270,  82,  11,  88, 261,  86,  89,  73,  18, 297,\n",
      "         11,  90,  73, 265,  73, 280, 225,  54,  17,  86, 296, 291, 274,  77,\n",
      "         80,  81,  87, 268, 277,  76, 273,  69,  80,  73, 225,  82,  89,  72,\n",
      "        277,  93,  18, 225,  43,  86, 294,  88, 291,  16, 266,  93, 269,  82,\n",
      "         80,  93, 288,  74, 271, 265,  83,  81,  73, 274,  80,  73,  73,  88,\n",
      "        278, 225,  90,  77,  73,  91,  87,  16, 272,  89,  88, 268, 263, 267,\n",
      "        262, 267, 266, 225,  54,  17,  86, 296, 291, 274,  77,  80,  81,  87,\n",
      "        268, 277,  76, 225,  75,  69,  84, 278, 225,  90,  89,  80,  90, 295,\n",
      "        290, 274,  80,  69,  84,  84, 278, 292,  69,  70,  77,  69,  35, 225,\n",
      "         50,  83,  91, 263, 267,  16, 272,  73,  71,  69,  89,  87,  73, 266,\n",
      "         93, 289, 284,  11,  88, 225,  73,  92, 270,  88,  18, 225,  56, 263,\n",
      "        265,  69,  81,  73, 225,  75,  83, 283, 274, 281, 261,  76,  83,  87,\n",
      "         73, 279,  86,  69,  84,  84,  93, 279,  69,  70,  80,  73, 265,  76,\n",
      "         83,  91,  87,  30, 265,  71,  76,  80, 284,  75,  87, 265,  91, 278,\n",
      "        278, 293, 266, 272, 267,  73,  94,  73, 272,  89,  88, 225,  82,  83,\n",
      "         88, 262, 279,  80, 277, 281, 270, 293, 265,  77,  75,  76,  88,  18,\n",
      "        225,  37, 275, 261,  76,  83,  87,  73, 287, 267,  88, 280,  88,  77,\n",
      "        282,  87, 293,  72,  77,  73, 273,  83,  90,  77, 283, 292,  77,  79,\n",
      "         73, 225,  56, 263, 225,  38,  86,  83,  91,  82, 225,  38,  89,  82,\n",
      "         82,  93,  16, 293, 268,  76,  77,  71,  76, 268,  73,  11, 267, 261,\n",
      "        267, 296, 291, 285, 266, 265, 277,  73, 288, 225,  58, 264,  71, 280,\n",
      "         88, 225,  43,  69, 286,  83,  11,  87, 261,  76,  86,  83,  70,  70,\n",
      "        278, 225,  78,  83,  76,  82,  87, 284,  16, 272,  89,  88, 225,  82,\n",
      "         83,  88, 262, 261,  86,  69,  71,  73, 288, 287, 264,  79, 225,  90,\n",
      "        270,  77,  70,  80,  73, 269,  82, 225,  39,  76,  80,  83,  73, 225,\n",
      "         55,  73,  90,  77,  75,  82,  93,  18, 225,  38,  73,  74,  83, 267,\n",
      "        279,  86,  93, 278, 225,  12, 281, 225,  77,  81,  84,  80,  93, 278,\n",
      "         13, 225,   6,  72, 282,  70,  80,  73,  17,  87,  88,  69, 275,  69,\n",
      "         86,  72,   6, 293, 273, 296,  88, 271,  87, 288, 225,  82,  89,  72,\n",
      "        277,  93,  16, 266, 273, 280,  88,  69, 286,  93, 269,  70,  88,  89,\n",
      "         87,  73, 265,  76, 282,  80,  72, 261,  69,  79,  73, 293,  88,  83,\n",
      "        262,  71,  71, 282,  82,  88, 269,  82,  73, 225,  89,  82,  69,  90,\n",
      "         83,  77,  72,  69,  70,  80,  93, 269,  70,  90,  77, 282,  87, 262,\n",
      "         82, 296,  83,  81,  77,  71,  69,  80, 289,  77,  74,  74,  73, 267,\n",
      "         82,  71,  73, 272,  73,  88,  91,  73, 280, 273, 280, 290, 268,  83,\n",
      "         81, 280,  30, 266, 267, 262, 267, 225,  82,  83, 225,  75, 280, 277,\n",
      "         69,  80,  87, 269,  82, 289, 270,  84,  80,  69,  93, 268, 263,  82,\n",
      "        262,  71,  88, 267,  87,  87, 283, 262,  84,  84,  73,  69,  86,  87,\n",
      "        225,  82,  89,  72,  73,  16, 290, 266, 265,  69,  81,  73, 279, 294,\n",
      "         82,  83,  88, 272,  73, 265,  69,  77,  72, 274, 281, 262, 273, 294,\n",
      "         18, 297,  82, 274,  69,  71,  88,  16, 225,  93, 282, 225,  75, 280,\n",
      "        271,  69, 286,  93, 268, 284,  11,  88, 265,  73,  73, 274,  73,  81,\n",
      "         69,  80,  73, 225,  75, 280, 277,  69,  80,  87, 293, 262,  82, 225,\n",
      "         37,  81, 271,  77,  71, 294, 274,  77,  80,  81, 293, 262,  82,  93,\n",
      "         88,  76, 278, 265,  76, 281,  88, 288, 287, 281,  82, 269,  86, 225,\n",
      "         73,  92,  84,  80,  77,  71, 277, 225, 271,  83,  88,  77,  71,  69,\n",
      "         18, 225,  56,  76, 270, 262, 286,  73,  75, 291, 289, 282,  70,  80,\n",
      "         73,  17,  87,  88,  69, 275,  69,  86,  72, 225, 270, 292, 283,  87,\n",
      "        262, 289, 282,  70,  80,  73, 265,  88,  69, 275,  69,  86,  72, 261,\n",
      "        276,  82, 262,  82, 262,  72,  81, 277,  88, 291,  80,  93, 289,  73,\n",
      "         84, 267,  87,  87, 278, 262,  70,  77,  80, 277,  93, 285, 279,  83,\n",
      "         81,  73, 285, 261, 271,  81,  87, 279,  89,  80,  88,  89,  86,  69,\n",
      "        286,  93, 268, 277,  76, 266, 293,  87,  77,  72, 283, 288, 268,  83,\n",
      "         81, 280,  11,  87, 272,  83,  72,  77, 283,  18], device='cuda:0')}, tensor([2], device='cuda:0'))\n"
     ]
    }
   ],
   "source": [
    "train_data = []\n",
    "n_max = 100\n",
    "for i, (label, line) in enumerate(train_iter):\n",
    "    if i >= n_max:\n",
    "        break\n",
    "    token_ids = tokenizer.encode(line).ids\n",
    "    token_ids = torch.LongTensor(token_ids).to('cuda')\n",
    "    train_data.append(({'input_ids': token_ids}, torch.LongTensor(label).to('cuda')))\n",
    "train_loader = torch.utils.data.DataLoader(train_data)\n",
    "\n",
    "print(len(train_data))\n",
    "print(train_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875c90db-4872-4dd2-8039-eeb16a7ef467",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a8757d72",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-18T20:35:52.374984Z",
     "iopub.status.busy": "2024-03-18T20:35:52.374816Z",
     "iopub.status.idle": "2024-03-18T20:35:52.407924Z",
     "shell.execute_reply": "2024-03-18T20:35:52.407542Z",
     "shell.execute_reply.started": "2024-03-18T20:35:52.374974Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dataset import IMDbDataModule\n",
    "\n",
    "BATCH_SIZE = 4\n",
    "max_seq_len = 16\n",
    "n_examples_max = 16\n",
    "#n_examples_max = 8 # for quick tests\n",
    "#n_examples_max = None\n",
    "\n",
    "dm = IMDbDataModule(val_split=0.2,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    max_seq_length=max_seq_len,\n",
    "                    n_examples_max=n_examples_max)\n",
    "# train_loader = torch.utils.data.DataLoader(train_data)\n",
    "train_loader = torch.utils.data.DataLoader(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ceea2a1d-15b0-44ad-a8a9-8b477df4d2a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-18T19:12:33.941734Z",
     "iopub.status.busy": "2024-03-18T19:12:33.941195Z",
     "iopub.status.idle": "2024-03-18T19:12:33.978715Z",
     "shell.execute_reply": "2024-03-18T19:12:33.978305Z",
     "shell.execute_reply.started": "2024-03-18T19:12:33.941720Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'input_ids': tensor([[297, 225, 267,  ...,  83,  88,  18]], device='cuda:0')},\n",
       " tensor([1])]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "661aeb97",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-18T19:12:35.298875Z",
     "iopub.status.busy": "2024-03-18T19:12:35.298572Z",
     "iopub.status.idle": "2024-03-18T19:12:35.585971Z",
     "shell.execute_reply": "2024-03-18T19:12:35.585495Z",
     "shell.execute_reply.started": "2024-03-18T19:12:35.298863Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/idies/miniconda3/envs/qml/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/logger_connector/logger_connector.py:75: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `lightning.pytorch` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n"
     ]
    }
   ],
   "source": [
    "import lightning as L\n",
    "\n",
    "trainer = L.Trainer(\n",
    "    max_epochs=10,\n",
    "    accelerator='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "90ff0149",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-18T20:48:46.457490Z",
     "iopub.status.busy": "2024-03-18T20:48:46.457230Z",
     "iopub.status.idle": "2024-03-18T20:48:49.007391Z",
     "shell.execute_reply": "2024-03-18T20:48:49.006873Z",
     "shell.execute_reply.started": "2024-03-18T20:48:46.457479Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from models import GPT2, IMDbClassifier\n",
    "\n",
    "embed_dim = 8\n",
    "vocab_size = 2000\n",
    "n_tlayers = 1\n",
    "n_heads = 2\n",
    "lr = 1e-3\n",
    "\n",
    "classifier = IMDbClassifier(embed_dim=embed_dim,\n",
    "                       vocab_size=vocab_size,\n",
    "                       n_heads=n_heads,\n",
    "                       n_tlayers=n_tlayers,\n",
    "                       max_seq_len=max_seq_len\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c22c73e8-895a-4c65-919c-e4bcf0e8509b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-18T20:40:26.710416Z",
     "iopub.status.busy": "2024-03-18T20:40:26.710156Z",
     "iopub.status.idle": "2024-03-18T20:40:26.742309Z",
     "shell.execute_reply": "2024-03-18T20:40:26.741864Z",
     "shell.execute_reply.started": "2024-03-18T20:40:26.710405Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "classifier.to('cuda')\n",
    "print(classifier.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f55ed28e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-18T20:48:49.012170Z",
     "iopub.status.busy": "2024-03-18T20:48:49.011932Z",
     "iopub.status.idle": "2024-03-18T20:48:49.691131Z",
     "shell.execute_reply": "2024-03-18T20:48:49.690504Z",
     "shell.execute_reply.started": "2024-03-18T20:48:49.012158Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | wte     | Embedding  | 2.4 K \n",
      "1 | wpe     | Embedding  | 128   \n",
      "2 | dropout | Dropout    | 0     \n",
      "3 | ln_f    | LayerNorm  | 16    \n",
      "4 | h       | ModuleList | 872   \n",
      "5 | out     | Linear     | 16.0 K\n",
      "---------------------------------------\n",
      "19.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "19.4 K    Total params\n",
      "0.078     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/100 [41:20<?, ?it/s] \n",
      "Epoch 0:   0%|          | 0/100 [40:23<?, ?it/s]\n",
      "Epoch 0:   0%|          | 0/100 [40:08<?, ?it/s]\n",
      "Epoch 0:   0%|          | 0/100 [38:43<?, ?it/s]\n",
      "Epoch 0:   0%|          | 0/100 [37:43<?, ?it/s]\n",
      "Epoch 0:   0%|          | 0/100 [15:08<?, ?it/s]\n",
      "Epoch 0:   0%|          | 0/100 [11:58<?, ?it/s]\n",
      "Epoch 0:   0%|          | 0/100 [07:49<?, ?it/s]\n",
      "Epoch 0:   0%|          | 0/100 [04:08<?, ?it/s]\n",
      "Epoch 0:   0%|          | 0/100 [01:08<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "0D or 1D target tensor expected, multi-target not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[74], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m classifier\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m trainer \u001b[38;5;241m=\u001b[39m L\u001b[38;5;241m.\u001b[39mTrainer(\n\u001b[1;32m      3\u001b[0m     max_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[1;32m      4\u001b[0m     accelerator\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclassifier\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/qml/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py:544\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    542\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m TrainerStatus\u001b[38;5;241m.\u001b[39mRUNNING\n\u001b[1;32m    543\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 544\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    545\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    546\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/qml/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py:44\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     43\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     47\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[0;32m~/miniconda3/envs/qml/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py:580\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    574\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    575\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[1;32m    576\u001b[0m     ckpt_path,\n\u001b[1;32m    577\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    578\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    579\u001b[0m )\n\u001b[0;32m--> 580\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[1;32m    583\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/qml/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py:987\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    982\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_signal_connector\u001b[38;5;241m.\u001b[39mregister_signal_handlers()\n\u001b[1;32m    984\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    985\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[1;32m    986\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m--> 987\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    989\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    990\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[1;32m    991\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    992\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: trainer tearing down\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/qml/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py:1033\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1031\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_sanity_check()\n\u001b[1;32m   1032\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n\u001b[0;32m-> 1033\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1034\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1035\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnexpected state \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/qml/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py:205\u001b[0m, in \u001b[0;36m_FitLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start()\n\u001b[0;32m--> 205\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_restarting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/qml/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py:363\u001b[0m, in \u001b[0;36m_FitLoop.advance\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_training_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_fetcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 363\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepoch_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_fetcher\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/qml/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py:140\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.run\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone:\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 140\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end(data_fetcher)\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_restarting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/qml/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py:250\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.advance\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_training_batch\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mlightning_module\u001b[38;5;241m.\u001b[39mautomatic_optimization:\n\u001b[1;32m    249\u001b[0m         \u001b[38;5;66;03m# in automatic optimization, there can only be one optimizer\u001b[39;00m\n\u001b[0;32m--> 250\u001b[0m         batch_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautomatic_optimization\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    252\u001b[0m         batch_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmanual_optimization\u001b[38;5;241m.\u001b[39mrun(kwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/qml/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py:190\u001b[0m, in \u001b[0;36m_AutomaticOptimization.run\u001b[0;34m(self, optimizer, batch_idx, kwargs)\u001b[0m\n\u001b[1;32m    183\u001b[0m         closure()\n\u001b[1;32m    185\u001b[0m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;66;03m# BACKWARD PASS\u001b[39;00m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;66;03m# gradient update with accumulated gradients\u001b[39;00m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 190\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_optimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    192\u001b[0m result \u001b[38;5;241m=\u001b[39m closure\u001b[38;5;241m.\u001b[39mconsume_result()\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mloss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/qml/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py:268\u001b[0m, in \u001b[0;36m_AutomaticOptimization._optimizer_step\u001b[0;34m(self, batch_idx, train_step_and_backward_closure)\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptim_progress\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep\u001b[38;5;241m.\u001b[39mincrement_ready()\n\u001b[1;32m    267\u001b[0m \u001b[38;5;66;03m# model hook\u001b[39;00m\n\u001b[0;32m--> 268\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_lightning_module_hook\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moptimizer_step\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_step_and_backward_closure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m should_accumulate:\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptim_progress\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep\u001b[38;5;241m.\u001b[39mincrement_completed()\n",
      "File \u001b[0;32m~/miniconda3/envs/qml/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py:157\u001b[0m, in \u001b[0;36m_call_lightning_module_hook\u001b[0;34m(trainer, hook_name, pl_module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m hook_name\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[LightningModule]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpl_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 157\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m    160\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m prev_fx_name\n",
      "File \u001b[0;32m~/miniconda3/envs/qml/lib/python3.11/site-packages/lightning/pytorch/core/module.py:1303\u001b[0m, in \u001b[0;36mLightningModule.optimizer_step\u001b[0;34m(self, epoch, batch_idx, optimizer, optimizer_closure)\u001b[0m\n\u001b[1;32m   1264\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimizer_step\u001b[39m(\n\u001b[1;32m   1265\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1266\u001b[0m     epoch: \u001b[38;5;28mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1269\u001b[0m     optimizer_closure: Optional[Callable[[], Any]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1270\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1271\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Override this method to adjust the default way the :class:`~lightning.pytorch.trainer.trainer.Trainer` calls\u001b[39;00m\n\u001b[1;32m   1272\u001b[0m \u001b[38;5;124;03m    the optimizer.\u001b[39;00m\n\u001b[1;32m   1273\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1301\u001b[0m \n\u001b[1;32m   1302\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1303\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer_closure\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/qml/lib/python3.11/site-packages/lightning/pytorch/core/optimizer.py:152\u001b[0m, in \u001b[0;36mLightningOptimizer.step\u001b[0;34m(self, closure, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MisconfigurationException(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhen `optimizer.step(closure)` is called, the closure should be callable\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_strategy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 152\u001b[0m step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_strategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_on_after_step()\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m step_output\n",
      "File \u001b[0;32m~/miniconda3/envs/qml/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py:239\u001b[0m, in \u001b[0;36mStrategy.optimizer_step\u001b[0;34m(self, optimizer, closure, model, **kwargs)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;66;03m# TODO(fabric): remove assertion once strategy's optimizer_step typing is fixed\u001b[39;00m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, pl\u001b[38;5;241m.\u001b[39mLightningModule)\n\u001b[0;32m--> 239\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprecision_plugin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/qml/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py:122\u001b[0m, in \u001b[0;36mPrecision.optimizer_step\u001b[0;34m(self, optimizer, model, closure, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Hook to run the optimizer step.\"\"\"\u001b[39;00m\n\u001b[1;32m    121\u001b[0m closure \u001b[38;5;241m=\u001b[39m partial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_closure, model, optimizer, closure)\n\u001b[0;32m--> 122\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/qml/lib/python3.11/site-packages/torch/optim/optimizer.py:385\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    381\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    382\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    383\u001b[0m             )\n\u001b[0;32m--> 385\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    388\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/qml/lib/python3.11/site-packages/torch/optim/optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m~/miniconda3/envs/qml/lib/python3.11/site-packages/torch/optim/adam.py:146\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m closure \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39menable_grad():\n\u001b[0;32m--> 146\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_groups:\n\u001b[1;32m    149\u001b[0m     params_with_grad \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/miniconda3/envs/qml/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py:108\u001b[0m, in \u001b[0;36mPrecision._wrap_closure\u001b[0;34m(self, model, optimizer, closure)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_wrap_closure\u001b[39m(\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     97\u001b[0m     model: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpl.LightningModule\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     98\u001b[0m     optimizer: Optimizer,\n\u001b[1;32m     99\u001b[0m     closure: Callable[[], Any],\n\u001b[1;32m    100\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    101\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"This double-closure allows makes sure the ``closure`` is executed before the ``on_before_optimizer_step``\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;124;03m    hook is called.\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    106\u001b[0m \n\u001b[1;32m    107\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 108\u001b[0m     closure_result \u001b[38;5;241m=\u001b[39m \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_after_closure(model, optimizer)\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m closure_result\n",
      "File \u001b[0;32m~/miniconda3/envs/qml/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py:144\u001b[0m, in \u001b[0;36mClosure.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[Tensor]:\n\u001b[0;32m--> 144\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\u001b[38;5;241m.\u001b[39mloss\n",
      "File \u001b[0;32m~/miniconda3/envs/qml/lib/python3.11/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/qml/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py:129\u001b[0m, in \u001b[0;36mClosure.closure\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39menable_grad()\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclosure\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ClosureResult:\n\u001b[0;32m--> 129\u001b[0m     step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_step_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m step_output\u001b[38;5;241m.\u001b[39mclosure_loss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    132\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwarning_cache\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`training_step` returned `None`. If this was on purpose, ignore this warning...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/qml/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py:318\u001b[0m, in \u001b[0;36m_AutomaticOptimization._training_step\u001b[0;34m(self, kwargs)\u001b[0m\n\u001b[1;32m    315\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\n\u001b[1;32m    317\u001b[0m \u001b[38;5;66;03m# manually capture logged metrics\u001b[39;00m\n\u001b[0;32m--> 318\u001b[0m training_step_output \u001b[38;5;241m=\u001b[39m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_strategy_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtraining_step\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mpost_training_step()  \u001b[38;5;66;03m# unused hook - call anyway for backward compatibility\u001b[39;00m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_result_cls\u001b[38;5;241m.\u001b[39mfrom_training_step_output(training_step_output, trainer\u001b[38;5;241m.\u001b[39maccumulate_grad_batches)\n",
      "File \u001b[0;32m~/miniconda3/envs/qml/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py:309\u001b[0m, in \u001b[0;36m_call_strategy_hook\u001b[0;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Strategy]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 309\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m    312\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m prev_fx_name\n",
      "File \u001b[0;32m~/miniconda3/envs/qml/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py:391\u001b[0m, in \u001b[0;36mStrategy.training_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module:\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_redirection(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining_step\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 391\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlightning_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/Storage/sjyoo/qml/repos/gh/gpt-q/models.py:385\u001b[0m, in \u001b[0;36mIMDbClassifierBase.training_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m    383\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(x)\n\u001b[1;32m    384\u001b[0m probs \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mlog_softmax(logits, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 385\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnll_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/miniconda3/envs/qml/lib/python3.11/site-packages/torch/nn/functional.py:2733\u001b[0m, in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2731\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2732\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 2733\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnll_loss_nd\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: 0D or 1D target tensor expected, multi-target not supported"
     ]
    }
   ],
   "source": [
    "classifier.to('cuda')\n",
    "trainer = L.Trainer(\n",
    "    max_epochs=10,\n",
    "    accelerator='gpu')\n",
    "trainer.fit(classifier, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "558a808c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-18T19:11:23.336381Z",
     "iopub.status.busy": "2024-03-18T19:11:23.335583Z",
     "iopub.status.idle": "2024-03-18T19:11:23.387883Z",
     "shell.execute_reply": "2024-03-18T19:11:23.387280Z",
     "shell.execute_reply.started": "2024-03-18T19:11:23.336327Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(classifier.state_dict(), \"imdb_classifier.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b53e115",
   "metadata": {},
   "source": [
    "## IMBd Classifier Quantum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "86b43618",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import GPTQ, IMDbClassifierQuantum\n",
    "\n",
    "n_qlayers = 1\n",
    "q_device = 'qulacs.simulator'\n",
    "\n",
    "classifier_quantum = IMDbClassifierQuantum(embed_dim=embed_dim,\n",
    "                       vocab_size=vocab_size,\n",
    "                       n_heads=n_heads,\n",
    "                       n_tlayers=n_tlayers,\n",
    "                       max_seq_len=max_seq_len,\n",
    "                       q_device=q_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614c879b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | wte     | Embedding  | 2.4 K \n",
      "1 | wpe     | Embedding  | 128   \n",
      "2 | dropout | Dropout    | 0     \n",
      "3 | ln_f    | LayerNorm  | 16    \n",
      "4 | h       | ModuleList | 51    \n",
      "5 | out     | Linear     | 16.0 K\n",
      "---------------------------------------\n",
      "18.6 K    Trainable params\n",
      "0         Non-trainable params\n",
      "18.6 K    Total params\n",
      "0.074     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|                                                                                                                                                                                                            | 0/100 [28:51<?, ?it/s]\n",
      "Epoch 0:   0%|                                                                                                                                                                                                            | 0/100 [21:33<?, ?it/s]\n",
      "Epoch 0:   0%|                                                                                                                                                                                                            | 0/100 [14:54<?, ?it/s]\n",
      "Epoch 0:   0%|                                                                                                                                                                                                            | 0/100 [08:48<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "trainer_quantum = L.Trainer(\n",
    "    max_epochs=10,\n",
    "    accelerator='auto')\n",
    "\n",
    "trainer_quantum.fit(classifier_quantum, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c56a5d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(classifier_quantum.state_dict(), \"imdb_classifier_quantum.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85b50d3",
   "metadata": {},
   "source": [
    "## Fit Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "586234df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import LanguageModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "487b067c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 2000\n",
    "max_seq_len = 64\n",
    "n_layers = 1\n",
    "n_heads = 2\n",
    "lr = 1e-3\n",
    "\n",
    "model = LanguageModel(embed_dim=embed_dim,\n",
    "                       vocab_size=vocab_size,\n",
    "                       n_heads=n_heads,\n",
    "                       n_layers=n_layers,\n",
    "                       max_seq_len=max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91f62b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "QML",
   "language": "python",
   "name": "qml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
