{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c870a6ec",
   "metadata": {},
   "source": [
    "# GPT-Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "0f8a9309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "324f9f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pennylane import numpy as np\n",
    "\n",
    "torch.set_printoptions(precision=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "35664602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0: ──RX(0)──RX(2.51)──╭C──────────────╭X──┤ ⟨Z⟩ \n",
      " 1: ──RX(0)──RX(5.39)──╰X──╭C──────────│───┤ ⟨Z⟩ \n",
      " 2: ──RX(0)──RX(2.11)──────╰X──╭C──────│───┤ ⟨Z⟩ \n",
      " 3: ──RX(0)──RX(5.71)──────────╰X──╭C──│───┤     \n",
      " 4: ──RX(0)──RX(2.8)───────────────╰X──╰C──┤     \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from models import QConv1d\n",
    "\n",
    "ks = 5  # kind of arbitrary, limited by the number of available qubits\n",
    "p = (ks - 1) // 2\n",
    "\n",
    "qconv = QConv1d(kernel_size=ks, out_channels=3, n_qlayers=1, stride=1, padding=p)\n",
    "qconv.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "622958c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 8])\n",
      "tensor([[[0.724, 0.739, 0.477, 0.790, 0.803, 0.830, 0.525, 0.619],\n",
      "         [0.950, 0.038, 0.559, 0.566, 0.529, 0.111, 0.921, 0.880],\n",
      "         [0.614, 0.241, 0.059, 0.060, 0.146, 0.071, 0.527, 0.055],\n",
      "         [0.231, 0.916, 0.745, 0.830, 0.980, 0.313, 0.296, 0.817]]])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1\n",
    "seq_len = 4\n",
    "embed_dim = 8\n",
    "x = torch.rand((batch_size, seq_len, embed_dim))\n",
    "print(x.shape)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "9bbe70b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 8, 3])\n"
     ]
    }
   ],
   "source": [
    "z = qconv(x)\n",
    "print(z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "1717b98a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 8])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z[:, :, :, 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "64024bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 24])\n"
     ]
    }
   ],
   "source": [
    "zc = z.view((1, 4, embed_dim*3))\n",
    "print(zc.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a458aa9",
   "metadata": {},
   "source": [
    "1 + (c*w + 2*p - k) / s = w\n",
    "=> (c*w - k) / s = w - 1\n",
    "=> s = (c*w - k) / (w - 1)\n",
    "this has to be an integer.\n",
    "\n",
    "n = (c*w - k) / (w - 1) => n * (w - 1) = c*w - k => k = c*w - n * (w - 1)\n",
    "k = (3 - n) * w + n, 0 < k < 3*w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "c347f5b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "25\n",
      "18\n",
      "11\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "def find_k(w, c):\n",
    "    for n in range(10):\n",
    "        # n = (b*w - k) / (d - 1) => n * (d - 1) = b*w - k => k = b*w - n*w + n\n",
    "        k = c*w - n * (w - 1)\n",
    "        if k < 0:\n",
    "            break\n",
    "        print(k)\n",
    "\n",
    "find_k(embed_dim, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "f1ab88b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernel size (=no. of qubits): 3\n",
      "stride: 3\n",
      " 0: ──RX(0)──RX(4)─────╭C──────╭X──┤ ⟨Z⟩ \n",
      " 1: ──RX(0)──RX(5.23)──╰X──╭C──│───┤     \n",
      " 2: ──RX(0)──RX(1.18)──────╰X──╰C──┤     \n",
      "\n"
     ]
    }
   ],
   "source": [
    "ks_inv = 3\n",
    "stride_inv = (3 * embed_dim - ks_inv) // (embed_dim - 1)\n",
    "print(f\"kernel size (=no. of qubits): {ks_inv}\")\n",
    "print(f\"stride: {stride_inv}\")\n",
    "qconv_inv = QConv1d(kernel_size=ks_inv, out_channels=1, n_qlayers=1, stride=stride_inv, padding=0)\n",
    "qconv_inv.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "1c95e90b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 16])\n"
     ]
    }
   ],
   "source": [
    "y = qconv_inv(zc).view((batch_size, seq_len, -1))\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "d9fce9ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0,  1,  2],\n",
      "          [ 3,  4,  5],\n",
      "          [ 6,  7,  8],\n",
      "          [ 9, 10, 11]],\n",
      "\n",
      "         [[12, 13, 14],\n",
      "          [15, 16, 17],\n",
      "          [18, 19, 20],\n",
      "          [21, 22, 23]]]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(24).view(1, 2, 4, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "cdd22b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0,  3,  6,  9],\n",
      "          [ 1,  4,  7, 10],\n",
      "          [ 2,  5,  8, 11]],\n",
      "\n",
      "         [[12, 15, 18, 21],\n",
      "          [13, 16, 19, 22],\n",
      "          [14, 17, 20, 23]]]])\n",
      "tensor([[[ 0,  3,  6,  9,  1,  4,  7, 10,  2,  5,  8, 11],\n",
      "         [12, 15, 18, 21, 13, 16, 19, 22, 14, 17, 20, 23]]])\n"
     ]
    }
   ],
   "source": [
    "x = x.transpose(-1,-2).view(1,2,3,-1)\n",
    "print(x)\n",
    "x = x.reshape((1,2,12))\n",
    "print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "4b0cfc63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.442, -0.503,  0.480,  0.431, -0.795,  0.431,  0.586, -0.649,\n",
      "           0.641,  0.852, -0.828,  0.821,  0.506, -0.971,  0.555,  0.372,\n",
      "          -0.654,  0.404,  0.421, -0.611,  0.379,  0.507, -0.633,  0.561],\n",
      "         [ 0.540, -0.503,  0.497,  0.548, -0.806,  0.511,  0.384, -0.712,\n",
      "           0.398,  0.428, -0.592,  0.407,  0.542, -0.655,  0.460,  0.604,\n",
      "          -0.728,  0.635,  0.577, -0.861,  0.571,  0.567, -0.755,  0.711],\n",
      "         [ 0.408, -0.503,  0.346,  0.750, -0.630,  0.618,  0.773, -0.916,\n",
      "           0.789,  0.720, -0.903,  0.795,  0.853, -0.930,  0.903,  0.748,\n",
      "          -0.991,  0.957,  0.502, -0.980,  0.541,  0.510, -0.655,  0.637],\n",
      "         [ 0.455, -0.503,  0.457,  0.861, -0.772,  0.748,  0.948, -0.993,\n",
      "           0.989,  0.702, -0.987,  0.752,  0.481, -0.802,  0.522,  0.545,\n",
      "          -0.715,  0.535,  0.716, -0.746,  0.722,  0.548, -0.942,  0.655]]],\n",
      "       grad_fn=<ViewBackward>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.442,  0.540,  0.408,  0.455],\n",
       "         [-0.503, -0.503, -0.503, -0.503],\n",
       "         [ 0.480,  0.497,  0.346,  0.457],\n",
       "         [ 0.431,  0.548,  0.750,  0.861],\n",
       "         [-0.795, -0.806, -0.630, -0.772],\n",
       "         [ 0.431,  0.511,  0.618,  0.748],\n",
       "         [ 0.586,  0.384,  0.773,  0.948],\n",
       "         [-0.649, -0.712, -0.916, -0.993],\n",
       "         [ 0.641,  0.398,  0.789,  0.989],\n",
       "         [ 0.852,  0.428,  0.720,  0.702],\n",
       "         [-0.828, -0.592, -0.903, -0.987],\n",
       "         [ 0.821,  0.407,  0.795,  0.752],\n",
       "         [ 0.506,  0.542,  0.853,  0.481],\n",
       "         [-0.971, -0.655, -0.930, -0.802],\n",
       "         [ 0.555,  0.460,  0.903,  0.522],\n",
       "         [ 0.372,  0.604,  0.748,  0.545],\n",
       "         [-0.654, -0.728, -0.991, -0.715],\n",
       "         [ 0.404,  0.635,  0.957,  0.535],\n",
       "         [ 0.421,  0.577,  0.502,  0.716],\n",
       "         [-0.611, -0.861, -0.980, -0.746],\n",
       "         [ 0.379,  0.571,  0.541,  0.722],\n",
       "         [ 0.507,  0.567,  0.510,  0.548],\n",
       "         [-0.633, -0.755, -0.655, -0.942],\n",
       "         [ 0.561,  0.711,  0.637,  0.655]]], grad_fn=<TransposeBackward0>)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(zc)\n",
    "zc.transpose(-1, -2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8f99a3",
   "metadata": {},
   "source": [
    "## FeedForward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "2bf4254b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import FeedForward\n",
    "\n",
    "ff = FeedForward(embed_dim, boom_factor=4, n_qubits=n_qubits, n_qlayers=n_qlayers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "3392302b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: torch.Size([1, 4, 8])\n",
      "output: torch.Size([1, 4, 8])\n"
     ]
    }
   ],
   "source": [
    "print(\"input:\", x.shape)\n",
    "xff = ff.forward(x)\n",
    "print(\"output:\", xff.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c936c5ae",
   "metadata": {},
   "source": [
    "## Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "8b2ff1e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 8])\n",
      "tensor([[[0.879, 0.937, 0.358, 0.162, 0.256, 0.023, 0.009, 0.436],\n",
      "         [0.235, 0.610, 0.020, 0.139, 0.899, 0.573, 0.740, 0.396],\n",
      "         [0.660, 0.636, 0.872, 0.478, 0.135, 0.023, 0.161, 0.089],\n",
      "         [0.044, 0.458, 0.573, 0.727, 0.283, 0.855, 0.989, 0.085]]])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1\n",
    "seq_len = 4\n",
    "embed_dim = 8\n",
    "x = torch.rand((batch_size, seq_len, embed_dim))\n",
    "print(x.shape)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "1ab28bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import MultiHeadAttention\n",
    "\n",
    "n_heads = 2\n",
    "n_qubits = 5\n",
    "n_qlayers = 1\n",
    "n_heads = 4\n",
    "\n",
    "attn = MultiHeadAttention(embed_dim, n_heads, n_qubits, n_qlayers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "3368526e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after qconv 1->3: torch.Size([1, 4, 8, 3])\n",
      "shapes: q: torch.Size([1, 4, 8]) k: torch.Size([1, 4, 8]) v: torch.Size([1, 4, 8])\n",
      "after split heads: torch.Size([1, 4, 4, 2]) torch.Size([1, 4, 4, 2]) torch.Size([1, 4, 4, 2])\n",
      "attention: torch.Size([1, 4, 4, 2])\n",
      "merged heads: torch.Size([1, 4, 8])\n",
      "attn output: torch.Size([1, 4, 8])\n",
      "output of attention: torch.Size([1, 4, 8])\n"
     ]
    }
   ],
   "source": [
    "out = attn(x)\n",
    "print(\"output of attention:\", out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c83ca17",
   "metadata": {},
   "source": [
    "## Transformer block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "bc818040",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import TransformerBlock\n",
    "\n",
    "transformer = TransformerBlock(embed_dim, n_heads=n_heads, n_qubits=n_qubits, n_qlayers=n_qlayers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "96e233d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after qconv 1->3: torch.Size([1, 4, 8, 3])\n",
      "shapes: q: torch.Size([1, 4, 8]) k: torch.Size([1, 4, 8]) v: torch.Size([1, 4, 8])\n",
      "after split heads: torch.Size([1, 4, 4, 2]) torch.Size([1, 4, 4, 2]) torch.Size([1, 4, 4, 2])\n",
      "attention: torch.Size([1, 4, 4, 2])\n",
      "merged heads: torch.Size([1, 4, 8])\n",
      "attn output: torch.Size([1, 4, 8])\n",
      "transformer block output: torch.Size([1, 4, 8])\n"
     ]
    }
   ],
   "source": [
    "x_tf = transformer.forward(x)\n",
    "print(\"transformer block output:\", x_tf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313fd74d",
   "metadata": {},
   "source": [
    "## GPT-Q Full Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "428c22dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import GPTQ\n",
    "\n",
    "batch_size = 1\n",
    "max_seq_len = 16\n",
    "vocab_size = 8\n",
    "n_targets = 4 \n",
    "n_layers = 2\n",
    "n_heads = 4\n",
    "\n",
    "gptq = GPTQ(embed_dim=embed_dim, vocab_size=vocab_size, output_dim=n_targets, n_heads=n_heads, n_layers=n_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "43de863c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6, 7, 5, 2, 2, 5, 3, 6, 6, 4, 0, 6, 4, 1, 2, 3]])\n"
     ]
    }
   ],
   "source": [
    "token_ids = np.random.choice(vocab_size, (batch_size, max_seq_len))\n",
    "token_ids = torch.tensor(token_ids)\n",
    "print(token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "bdd50111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after qconv 1->3: torch.Size([1, 16, 8, 3])\n",
      "shapes: q: torch.Size([1, 16, 8]) k: torch.Size([1, 16, 8]) v: torch.Size([1, 16, 8])\n",
      "after split heads: torch.Size([1, 4, 16, 2]) torch.Size([1, 4, 16, 2]) torch.Size([1, 4, 16, 2])\n",
      "attention: torch.Size([1, 4, 16, 2])\n",
      "merged heads: torch.Size([1, 16, 8])\n",
      "attn output: torch.Size([1, 16, 8])\n",
      "after qconv 1->3: torch.Size([1, 16, 8, 3])\n",
      "shapes: q: torch.Size([1, 16, 8]) k: torch.Size([1, 16, 8]) v: torch.Size([1, 16, 8])\n",
      "after split heads: torch.Size([1, 4, 16, 2]) torch.Size([1, 4, 16, 2]) torch.Size([1, 4, 16, 2])\n",
      "attention: torch.Size([1, 4, 16, 2])\n",
      "merged heads: torch.Size([1, 16, 8])\n",
      "attn output: torch.Size([1, 16, 8])\n",
      "output of transformer blocks: torch.Size([1, 16, 8])\n",
      "logits: torch.Size([1, 16, 4])\n",
      "GPT-Q output: torch.Size([1, 16, 4])\n"
     ]
    }
   ],
   "source": [
    "out = gptq(token_ids)\n",
    "print(\"GPT-Q output:\", out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3578f641",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
